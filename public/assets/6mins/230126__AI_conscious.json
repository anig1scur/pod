{
  "title": "AI have a mind of its own?",
  "img": "https://ichef.bbci.co.uk/images/ic/1200xn/p0dwpm5l.jpg",
  "url": "https://www.bbc.co.uk/learningenglish/english/features/6-minute-english_2023/ep-230126",
  "audio": "http://downloads.bbc.co.uk/learningenglish/features/6min/230126_6min_english_AI_conscious_download.mp3",
  "intro": [
    "Is artificial intelligence capable of consciousness? We\u2019ll hear from an expert who believes that AI is not as intelligent as we sometimes think, and as usual, we\u2019ll be learning some new vocabulary as well."
  ],
  "this_week_question": [
    "What happened to Blake Lemoine is strangely similar to the 2013 Hollywood movie, Her, starring Joaquin Phoenix as a lonely writer who talks with his computer, voiced by Scarlett Johansson. But what happens at the end of the movie? Is it:",
    "a)    the computer comes to life?",
    "b)    the computer dreams about the writer?  or,",
    "c)    the writer falls in love with the computer?",
    "Listen to the programme to find out the answer."
  ],
  "vocab": [
    {
      "text": "chatbot",
      "desc": "computer programme designed to have conversations with humans over the internet"
    },
    {
      "text": "cognitive",
      "desc": "connected with the mental processes of thinking, knowing, learning and understanding"
    },
    {
      "text": "wishful thinking",
      "desc": "something which is unlikely to come true in the future"
    },
    {
      "text": "anthropomorphise",
      "desc": "treat an animal or object as if it were human"
    },
    {
      "text": "blindsided",
      "desc": "unpleasantly surprised"
    },
    {
      "text": "get/be taken in (by) someone",
      "desc": "be deceived or tricked by someone"
    }
  ],
  "transcript": [
    {
      "author": "Sam",
      "text": "Hello. This is 6 Minute English from BBC Learning English. I\u2019m Sam."
    },
    {
      "author": "Neil",
      "text": "And I\u2019m Neil."
    },
    {
      "author": "Sam",
      "text": "In the autumn of 2021, something strange happened at the Google headquarters in California\u2019s Silicon Valley. A software engineer called, Blake Lemoine, was working on the artificial intelligence project, \u2018Language Models for Dialogue Applications\u2019, or LaMDA for short. LaMDA is a chatbot \u2013 a computer programme designed to have conversations with humans over the internet."
    },
    {
      "author": "Neil",
      "text": "After months talking with LaMDA on topics ranging from movies to the meaning of life, Blake came to a surprising conclusion: the chatbot was an intelligent person with wishes and rights that should be respected. For Blake, LaMDA was a Google employee, not a machine. He also called it his \u2018friend\u2019."
    },
    {
      "author": "Sam",
      "text": "Google quickly reassigned Blake from the project, announcing that his ideas were not supported by the evidence. But what exactly was going on?"
    },
    {
      "author": "Neil",
      "text": "In this programme, we\u2019ll be discussing whether artificial intelligence is capable of consciousness. We\u2019ll hear from one expert who thinks AI is not as intelligent as we sometimes think, and as usual, we\u2019ll be learning some new vocabulary as well."
    },
    {
      "author": "Sam",
      "text": "But before that, I have a question for you, Neil. What happened to Blake Lemoine is strangely similar to the 2013 Hollywood movie, Her, starring Joaquin Phoenix as a lonely writer who talks with his computer, voiced by Scarlett Johansson. But what happens at the end of the movie? Is it:"
    },
    {
      "author": "Neil",
      "text": "\u2026 c) the writer falls in love with the computer."
    },
    {
      "author": "Sam",
      "text": "OK, Neil, I\u2019ll reveal the answer at the end of the programme. Although Hollywood is full of movies about robots coming to life, Emily Bender, professor of linguistics and computing at the University of Washington, thinks AI isn\u2019t that smart. She thinks the words we use to talk about technology, phrases like \u2018machine learning\u2019, give a false impression about what computers can and can\u2019t do."
    },
    {
      "author": "Neil",
      "text": "Here is Professor Bender discussing another misleading phrase, \u2018speech recognition\u2019, with BBC World Service programme, The Inquiry:"
    },
    {
      "author": "Professor Emily Bender",
      "text": "If you talk about \u2018automatic speech recognition\u2019, the term \u2018recognition\u2019 suggests that there's something cognitive going on, where I think a better term would be automatic transcription. That just describes the input-output relation, and not any theory or wishful thinking about what the computer is doing to be able to achieve that."
    },
    {
      "author": "Sam",
      "text": "Using words like \u2018recognition\u2019 in relation to computers gives the idea that something cognitive is happening \u2013 something related to the mental processes of thinking, knowing, learning and understanding."
    },
    {
      "author": "Neil",
      "text": "But thinking and knowing are human, not machine, activities. Professor Benders says that talking about them in connection with computers is wishful thinking \u2013 something which is unlikely to happen."
    },
    {
      "author": "Sam",
      "text": "The problem with using words in this way is that it reinforces what Professor Bender calls, technical bias \u2013 the assumption that the computer is always right. When we encounter language that sounds natural, but is coming from a computer, humans can\u2019t help but imagine a mind behind the language, even when there isn\u2019t one."
    },
    {
      "author": "Neil",
      "text": "In other words, we anthropomorphise computers \u2013 we treat them as if they were human. Here\u2019s Professor Bender again, discussing this idea with Charmaine Cozier, presenter of BBC World Service\u2019s, the Inquiry."
    },
    {
      "author": "Professor Emily\u00a0Bender",
      "text": "Professor Emily Bender So \u2018ism\u2019 means system, \u2018anthro\u2019 or \u2018anthropo\u2019 means human, and \u2018morph\u2019 means shape\u2026 And so this is a system that puts the shape of a human on something, and in this case the something is a computer. We anthropomorphise animals all the time, but we also anthropomorphise action figures, or dolls, or companies when we talk about companies having intentions and so on. We very much are in the habit of seeing ourselves in the world around us."
    },
    {
      "author": "Charmaine Cozier",
      "text": "And while we\u2019re busy seeing ourselves by assigning human traits to things that are not, we risk being blindsided."
    },
    {
      "author": "Emily\u00a0Bender",
      "text": "Emily Bender The more fluent that text is, the more different topics it can converse on, the more chances there are to get taken in."
    },
    {
      "author": "Sam",
      "text": "If we treat computers as if they could think, we might get blindsided , or unpleasantly surprised. Artificial intelligence works by finding patterns in massive amounts of data, so it can seem like we\u2019re talking with a human, instead of a machine doing data analysis. As a result, we get taken in \u2013 we\u2019re tricked or deceived into thinking we\u2019re dealing with a human, or with something intelligent."
    },
    {
      "author": "Neil",
      "text": "Powerful AI can make machines appear conscious, but even tech giants like Google are years away from building computers that can dream or fall in love. Speaking of which, Sam, what was the answer to your question?"
    },
    {
      "author": "Sam",
      "text": "I asked what happened in the 2013 movie, Her. Neil thought that the main character falls in love with his computer, which was the correct answer!"
    },
    {
      "author": "Neil",
      "text": "OK. Right, it\u2019s time to recap the vocabulary we\u2019ve learned from this programme about AI, including chatbots - computer programmes designed to interact with humans over the internet."
    },
    {
      "author": "Sam",
      "text": "The adjective cognitive describes anything connected with the mental processes of knowing, learning and understanding."
    },
    {
      "author": "Neil",
      "text": "Wishful thinking means thinking that something which is very unlikely to happen might happen one day in the future."
    },
    {
      "author": "Sam",
      "text": "To anthropomorphise an object means to treat it as if it were human, even though it\u2019s not."
    },
    {
      "author": "Neil",
      "text": "When you\u2019re blindsided , you\u2019re surprised in a negative way."
    },
    {
      "author": "Sam",
      "text": "And finally, to get taken in by someone means to be deceived or tricked by them. My computer tells me that our six minutes are up! Join us again soon, for now it\u2019s goodbye from us."
    },
    {
      "author": "Neil",
      "text": "Bye!"
    }
  ],
  "authors": [
    "Sam",
    "Neil",
    "Professor Emily Bender",
    "Professor Emily\u00a0Bender",
    "Charmaine Cozier",
    "Emily\u00a0Bender"
  ]
}