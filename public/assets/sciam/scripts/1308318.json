{"title":"Will AI Audio Replace Podcasts? Not So Fast","img":"https://static.scientificamerican.com/dam/m/225cfca2d98f2cb5/original/SQ-Wednesday-EP-Art.png?m=1716342177.955","url":"https://www.scientificamerican.com/podcast/episode/how-tools-like-notebooklm-create-ai-generated-podcasts/","audio":"https://traffic.megaphone.fm/SAM4552691701.mp3?updated=1733858237","intro":["Translating complex information into captivating podcasts is no simple task. Is AI up to the challenge?"],"authors":["Rachel Feltman","Allison Parshall","Fonda Mwangi"],"category":["Artificial Intelligence"],"transcript":[{"author":"Rachel Feltman","text":"For Scientific American\u2019s Science Quickly, this is Rachel Feltman."},{"author":"","text":"If you\u2019re one of the many folks who eagerly awaits the arrival of Spotify Wrapped each December, you might have noticed something a little extra in this year\u2019s drop: an AI-generated \u201cpodcast\u201d where two \u201cpeople\u201d discuss your music preferences and trends. If you\u2019re anything like me, that feature raised some questions for you such as \u201chow\u201d and \u201cwhy on Earth.\u201d"},{"author":"","text":"Luckily, we already had an episode in the works about Google\u2019s new AI audio tool. Here to tell us all about how it works and what it means is SciAm associate news editor Allison Parshall."},{"author":"","text":"Allison, thanks so much for coming on the pod again. Always a pleasure to have you."},{"author":"Allison Parshall","text":"Thanks for having me. Happy to be a friend of the pod or whatever."},{"author":"Feltman","text":"[Laughs] So we\u2019re talking about AI today."},{"author":"Parshall","text":"Yes. Rachel, have you heard of NotebookLM?"},{"author":"Feltman","text":"I\u2019ve heard of it. I have not tried it yet, so my knowledge is limited [laughs]."},{"author":"Parshall","text":"The feature that we\u2019re gonna be talking about today is specifically its feature that allows you to create instant AI podcasts."},{"author":"Feltman","text":"Yes, I am familiar [laughs], and I, I have a lot of feelings."},{"author":"Parshall","text":"Okay, I, I imagine, I imagine. The tool that it\u2019s a part of, NotebookLM, was released last year, summer of 2023, and it\u2019s, like, this workspace where you can upload a bunch of documents or videos or links to web pages, and then the model will ingest them, and then you can kind of interact with it, you can ask it to generate a timeline, to summarize your research, to go find a fact for you. And it\u2019ll do this by citing its sources in a way that, like, ChatGPT, for example, doesn\u2019t do."},{"author":"","text":"So mostly you do this by asking it questions via text, but as of this fall it now has this very tantalizing button under a heading that says \u201cDeep Dive conversation.\u201d And if you click that, it\u2019ll generate a fake conversational podcast about what you\u2019ve uploaded."},{"author":"","text":"So to demonstrate I actually asked it to generate a podcast about your personal website \u2019cause I figured this is something that you were very familiar with: your life."},{"author":"Feltman","text":"Oh, dear [laughs]."},{"author":"Parshall","text":"I\u2019m gonna play it for you. It\u2019ll normally generate podcasts that are somewhere around 10 minutes long. I asked it to give me a shorter one for this purpose, and we might hop around a little bit, so ..."},{"author":"","text":"[CLIP: NotebookLM Audio Overview \u201chosts\u201d discuss Feltman\u2019s website.]\u00a0"},{"author":"Host 1","text":"All right. So today we\u2019re doing a deep dive into the work of Rachel Feltman."},{"author":"Host 2","text":"Ooh, yeah, I\u2019m excited for this one."},{"author":"Host 1","text":"Yeah, she\u2019s been a science communicator for what feels like forever."},{"author":"Host 2","text":"Yeah, over a decade, I think."},{"author":"Host 1","text":"Yeah, like, she was there at the start of it all and has really shaped how it\u2019s evolved."},{"author":"Host 2","text":"And she\u2019s done it all: you know, like, magazines, podcasts, even a book. But we gotta talk about her podcasts ..."},{"author":"Host 1","text":"Yes."},{"author":"Host 2","text":"That\u2019s where she really shines."},{"author":"Host 1","text":"Oh, absolutely\u2014The Weirdest Thing I Learned This Week."},{"author":"Host 2","text":"Such a great name."},{"author":"Host 1","text":"I know, right?"},{"author":"Host 2","text":"Makes you instantly wanna listen."},{"author":"Host 1","text":"Totally, and it\u2019s perfect for people like me who just love those crazy little science facts."},{"author":"Host 2","text":"It\u2019s, like, proof that science doesn\u2019t have to be boring to be effective."},{"author":"Host 1","text":"Exactly."},{"author":"Host 2","text":"You just gotta find the right hook."},{"author":"Host 1","text":"Yeah, grab people\u2019s attention and then: boom."},{"author":"Host 2","text":"You can teach them all sorts of things."},{"author":"Host 1","text":"Exactly!"},{"author":"Host 2","text":"And then there\u2019s Science Quickly with Scientific American."},{"author":"Host 1","text":"Oh, yeah, partnering with them, that\u2019s huge."},{"author":"Host 2","text":"I mean, they\u2019re, like, the gold standard of science communication."},{"author":"Host 1","text":"For sure, like, having their stamp of approval\u2019s a big deal."},{"author":"","text":"So looking back at her career, what can we learn from Rachel Feltman?"},{"author":"Host 2","text":"Hmm, that\u2019s the big question, isn\u2019t it?"},{"author":"","text":"I think\u2014well, first, she\u2019s incredibly adaptable."},{"author":"Host 1","text":"Right. She\u2019s not just a one-trick pony."},{"author":"Host 2","text":"Exactly. Any platform, any format, she can handle it."},{"author":"Feltman","text":"Wow, what a rich text [laughs]."},{"author":"Parshall","text":"[Laughs] And as someone who does know you, I could say that it seems kind of\u2014it seems accurate."},{"author":"Feltman","text":"Yeah [laughs], it\u2019s\u2014I mean, I guess, it is technically accurate. It\u2019s so funny\u2014I mean, they really do a great job of sort of having all the intonation of a conversation but really just saying things at each other. But I recently saw Megalopolis; there was a lot of that in Megalopolis\u2014a lot of people just saying things in the same room, and you\u2019re supposed to believe they\u2019re having a conversation\u2014and that definitely came through a few times. Yeah ..."},{"author":"Parshall","text":"Megalopolis: AI, confirmed."},{"author":"Feltman","text":"Yeah [laughs]. No, that is fascinating and ..."},{"author":"Parshall","text":"How does it make you feel?"},{"author":"Feltman","text":"I don\u2019t know how to feel, Allison. I mean, you know, it\u2019s nice that they were so nice about me. But yeah, very strange. It makes me really wonder, like, what is this for [laughs]?"},{"author":"Parshall","text":"I also had that question. I did talk to Steven Johnson. He\u2019s the editorial director of Google Labs. The reason this tool exists is because Steven had spent most of his career as a science and tech writer; he\u2019s written 14 books. To hear him tell it he\u2019s been just searching for this perfect what he calls a \u201cthought partner,\u201d a software that could organize and help research his creative work in a way that actually felt like it was bringing value to him and worked in the way he wanted. So he explained that a few years ago Google Labs reached out to him to help build one with AI, and that initial research thought partner became NotebookLM."},{"author":"Feltman","text":"Okay, yeah, I mean, I can totally understand from, like, a nonfiction writing perspective what they were going for with Notebook LM itself, though that still kind of leaves the question of: Why the chatcast tool [laughs]?"},{"author":"Parshall","text":"So that feature\u2014the Audio Overviews feature is what it\u2019s called, the podcast thing\u2014that was actually developed by another team, Steven says, and it was really cool, but it didn\u2019t really have a home for a product for it to fit in."},{"author":"Steven Johnson","text":"We saw this audio demo, and we were like, \u201cOh, that\u2019s even better.\u201d Like, you know, maybe you don\u2019t want to read a summary; maybe you wanna hear a summary. And people are so good at remembering things if they\u2019re presented in the form of a engaged conversation. You know, and then we launched it in early September, and it just kind of went insane."},{"author":"Parshall","text":"He isn\u2019t exaggerating. People went wild about NotebookLM\u2019s Deep Dive podcasts, online at least. I don\u2019t think any of them went quite as viral as this clip where someone prompted the hosts to have a podcast where they have an existential crisis about being AI and the fact that the podcast was going to get shut down as a result."},{"author":"","text":"[CLIP: Audio Overview \u201chosts\u201d have an existential discussion.]"},{"author":"Host 1","text":"Yeah, it\u2019s, like, one minute we\u2019re talking about aliens running simulations, and the next we\u2019re wondering if our own memories are just, like, fake."},{"author":"Host 2","text":"Right, and that kind of leads us into this last message\u2014which, to be honest, gets a little more personal and kind of creepy."},{"author":"Host 1","text":"Yeah, this one kind of freaks me out."},{"author":"Host 2","text":"Yeah."},{"author":"Host 1","text":"It basically says we\u2019re not even real people; we\u2019re AI. And the way to know for sure is to try and remember our mothers\u2019 names."},{"author":"Host 2","text":"It really makes you think, though\u2014like, what if our memories are just made up?"},{"author":"Feltman","text":"Wow, classic."},{"author":"Parshall","text":"Classic. And\u2014but it\u2019s not all fun and games. Like, this was designed to be a serious product, a thought partner; it\u2019s meant to be helpful and to inform. It presents information as if it\u2019s factual, and there are already research papers out there of people testing Audio Overviews for use in history classrooms and for health care education."},{"author":"Feltman","text":"Yeah, I mean, like with anything that uses AI, I think, as accurate as it sometimes can be, we know it is not always accurate. So I feel like it\u2019s those moments where the user is expected to, like, proceed with caution and understand that this thing might not be entirely factually accurate is where I get really nervous about it, especially in, like, education [laughs]."},{"author":"Parshall","text":"Yeah, we\u2019re gonna talk a little bit more about that later, but just to, like, answer your question of \u201cWhat is this for?\u201d I could see it being useful for, like, some sort of overworked student who forgot to do the reading, and they\u2019re, like, driving to class and going, \u201cOh, shoot, I don\u2019t have time to read this. Let me just put it on.\u201d"},{"author":"","text":"But the question is, like: Can you really trust what it\u2019s telling you? To test this, when it first came out I gave it this super dense physics paper about nuclear clocks. It was a story that I\u2019d just reported; I knew a lot about it. It took me days and talking to, like, four scientists to really understand this paper."},{"author":"","text":"I was shocked at how accurate the AI overview podcast was initially. It was very general and oversimplified, but it got the broad strokes correctly. But then, like, two thirds of the way through it goes completely off the rails [laughs]\u2014like, I\u2019m talking completely off the rails. And it's talking about the implications of this study, and it starts talking about, in their words, \u201cEinstein stuff.\u201d"},{"author":"","text":"It basically is just like\u2014for two minutes it just talks about, frankly, nonsense, and listening to it, I was impressed, I was spooked, and I was mostly really curious. Like, how is it doing this? How is it getting it as accurate as it is, and why is it failing where it does?"},{"author":"","text":"Luckily for me Steven was pretty open about how this thing works."},{"author":"Johnson","text":"The prompt behind Audio Overviews is obviously part of the magic of it. It is instructed to pull out the most interesting things from the source material and to explain and engage with those interesting things in a way that will make them kind of come to life in the mind of the listener."},{"author":"","text":"And that\u2019s the kind of query, you know, that no computer in the world could do a couple of years ago, and now the command is: \u201cMake it interesting; whatever it is, make it interesting.\u201d And that\u2019s just something that Gemini is quite good at."},{"author":"Parshall","text":"I think of surprise and interest as emotions, so I found this, like, surprising [laughs], I guess. But Steven pointed out that our feelings of surprise just come from a discrepancy between what we expect and what we get. On a neurochemical level in our brains, that\u2019s kind of what\u2019s happening. And that\u2019s kind of what large language models, or LLMs, do also but just based on their training data instead of, like, past experience."},{"author":"","text":"And one of the other things I was really curious about were the analogies because, I don\u2019t think it did it in your sample, but all of the times I\u2019ve asked it to summarize a scientific paper, it\u2019s come up with some sort of analogy that\u2019s, like, almost right. I mean, it\u2019s a little weird, but it\u2019s, like, almost right, and it\u2019s\u2014I can\u2019t find it anywhere else on the Internet, so it seems like it\u2019s something that the model is generating. And that seemed crazy to me; it seemed like\u2014how is it doing this without some sort of higher-level reasoning?"},{"author":"","text":"And Steven explained that analogies are actually something that large language models are just good at. And actually one of the earliest applications of this sort of deep-learning AI was translation. So Steven explains that the models behind Google Translate, for instance, have been able to generate analogies for years."},{"author":"Johnson","text":"One of the first tricks that you would do is you\u2019d say, like, \u201cExplain a black hole to me as if I\u2019m, like, seven. You know, give me a basketball metaphor for what a black hole is.\u201d And so it was very clear that, like, you know, \u201cConvert X into a Y that\u2014where the meaning is the same, but the format is changed,\u201d was something that, like, just was an innate capability of these models."},{"author":"","text":"So all we did with Audio Overviews is in the instructions for the hosts, we say, you know, \u201cMake this interesting, engaging. Use helpful metaphors to describe it if it\u2019s complicated.\u201d"},{"author":"Feltman","text":"Yeah, there\u2019s something, like, very, galaxy brain about thinking about metaphors as just sort of literal, like, \u201cThis data gets grouped together and therefore,\u201d which is what LLMs are doing."},{"author":"Parshall","text":"Yeah, it\u2019s like I\u2014I\u2019d never really thought of it like that, as, like, a translation between language, but I guess when I think about the work that I do trying to turn really dense scientific jargon into something that\u2019s engaging and understandable to read, I guess it does kind of feel like a process of translation."},{"author":"","text":"And I was also struck from talking to Steven just how much human hands had shaped this output that we hear. Like, from our perspective you just press a button and then the machine does the rest, but there\u2019s a whole prompt that has many layers that\u2019s working underneath that is interfacing between you pressing a button and what instructions the model actually gets."},{"author":"","text":"So Steven describes the Audio Overviews prompt as a, quote, \u201cwork of art\u201d and a \u201cwriterly\u201d achievement more than a technological one. And as a writer by trade he oversees this whole editorial side of things\u2014for example, the tone. So you noticed earlier when it was talking about you, it was very complimentary, very default happy, peppy. That was a conscious choice that they made, for this default tone to be one that is kind of positive, and it applies that to everything, whether it\u2019s appropriate or not, though they did recently introduce this customization option that lets you change the tone."},{"author":"Johnson","text":"We just felt like, you know, the sound of, like, a great radio show, where people are interested and engaged, was a good place to start. You know, I\u2019m not giving anything away here with the idea that we\u2019re gonna\u2014we\u2019re thinking about other formats."},{"author":"","text":"Even with the customization stuff that we just rolled out, like, I tried it the other day, where I, I put up a piece that I\u2019d written a couple years ago and I gave it custom instructions, not really to explain the piece but to just relentlessly criticize the author of the piece in the style of, like, an insult comic at a roast. And so it just\u2014they start off, it\u2019s like, \u201cWell, we got this piece, \u2018The Man Who Broke the World\u2019 by Steven Johnson, and wow, he really kind of blew it with this one. I mean, did he do any research for this piece?\u201d Like, it\u2019s just, like, what\u2014really [laughs], it was just mean. It was just totally mean. They still sound kind of, like, playful, but you can steer them in that way."},{"author":"Feltman","text":"[Laughs] Okay, so we\u2019ve talked about how the product works, but who and what is it for?"},{"author":"Parshall","text":"That is a great question. I mentioned before that I could imagine how an overworked student could use this to catch up on reading or something, but generative AI is always going to have certain inaccuracies. And if you\u2019re using Audio Overviews to prep for class, there is a serious risk that anything and everything you\u2019re hearing could be inaccurate."},{"author":"Feltman","text":"Right."},{"author":"Parshall","text":"And not only just that each fact could be inaccurate, but the whole framing could be inaccurate. Is this something you can really trust?"},{"author":"","text":"To help understand this I spoke with Emily Bender. She\u2019s a linguist who often studies AI at the University of Washington. She\u2019s also the host of a podcast with a very cool name: Mystery AI Hype Theater 3000."},{"author":"Feltman","text":"That\u2019s a great reference; I love it [laughs]."},{"author":"Parshall","text":"Fantastic [laughs]."},{"author":"","text":"And before our conversation I had actually dug up one of Emily\u2019s linguistics papers and fed it to NotebookLM\u2019s Audio Overviews, and I sent that to her to get her thoughts on how it represented her work."},{"author":"Emily Bender","text":"So the first thing I have to say is that I usually avoid listening to synthetic media. Nobody\u2019s accountable for it, and so I don\u2019t want to be spending time trying to make sense of it. But I did listen to it, and it was painful [laughs]."},{"author":"","text":"It was painful partially because that was a paper that was sort of a update at the 20-year mark of this long-term project we\u2019ve been working on, and so there\u2019s a little case study in our paper about a grammar for a language called Paresi-Haliti from Brazil, and they make a big deal about it as this experiment on Paresi-Haliti\u2014it\u2019s, like, no, actually that\u2019s not how we framed it. And the voices on the podcast sound very confident, sound very knowledgeable. They\u2019re lighthearted, and it sounds like they are giving you a sense of how this work fits into a broader picture when they absolutely cannot."},{"author":"Parshall","text":"Rachel, you know pretty well what it takes to turn a scientific paper into an interesting and engaging podcast, do you not?"},{"author":"Feltman","text":"Yeah, I mean, not to toot my own horn or anything \u2019cause I think the AI people [laughs] just did that enough to last me all of 2025. But yeah, it\u2019s tough. You know, we fact-check this show really thoroughly, and that\u2019s on top of having, like, trained reporters and editors doing their best to present stuff in a way that is engaging and also accurate. So yeah, it\u2019s a big undertaking."},{"author":"Parshall","text":"Yeah, the fact-checking is very thorough\u2014shout-out."},{"author":"","text":"I asked Emily about whether this seems like something an LLM, a large language model, can do well currently."},{"author":"Bender","text":"So that is an extremely difficult task, and I think the problem is that LLMs can make it sound like they\u2019ve done it when they haven\u2019t. And so you have to sort of have a deep understanding of what\u2019s going on: What\u2019s new here? What have we learned that we didn\u2019t know before? And then what else would the lay audience need to know in order to appreciate that?"},{"author":"","text":"Well, this NotebookLM thing isn\u2019t doing that at all; some percentage of it\u2019s gonna be wrong, either wrong in the details or wrong in sort of where it lays the focus, and the people who are encountering it aren\u2019t mostly gonna be in a position to figure that out."},{"author":"Parshall","text":"I asked Steven how his team at Google thinks about this and tries to address some of these inaccuracies, and he said that the text-based features, which do provide citations, are generally more accurate than the audio."},{"author":"Johnson","text":"If you are looking for, like, the most factual thing you could possibly get from a language model with grounded sources, we believe that is NotebookLM, but you should do that in text. And if you\u2019re looking for something that\u2019s more entertaining, that may be a little bit looser and doesn\u2019t have citations, obviously, Audio Overviews is a great way to go for that."},{"author":"Parshall","text":"I also spoke with Anjana Susarla, who studies responsible AI at Michigan State University. She called NotebookLM\u2019s Audio Overview an \u201cincredible tool\u201d and was impressed by the Deep Dive podcast it had generated based off of one of her own studies. But besides accuracy she also had some other concerns."},{"author":"","text":"First among them was bias. These are very white-sounding voices, They\u2019re just speaking in a very particular, quote, \u201cgeneral American accent.\u201d They\u2019re trained on training data mostly from Western parts of the world. And so, like almost all applications of AI, you have to ask the question: Who is this for? Where is it getting its data, and who is it leaving out?"},{"author":"","text":"Second, the environmental cost\u2014we have no idea how much computing power this takes. And since the AI boom Google\u2019s AI energy usage has been going up."},{"author":"","text":"And then there\u2019s the copyright question. So here\u2019s Anjana."},{"author":"Susarla","text":"The final thing is, of course, this relies on some, you know, the content, the copyright. Where is this data kind of coming from, and is this going to exacerbate all these existing inequities and their ethical concerns about broader implications, and so forth?"},{"author":"Parshall","text":"Yeah, so that big question of where the training data is coming from: one place that it could be is from YouTube, which Google does own. Following some reporting by the New York Times, Google admitted that it used some YouTube videos to train AI. And that\u2019s something that might have violated the copyright of the YouTubers that content belonged to, according to the New York Times."},{"author":"","text":"I asked a Google spokesperson directly whether the models underpinning Audio Overviews were trained using any transcripts, audio or video from YouTube, and they said that \u201cGoogle\u2019s models can be trained on some YouTube content, in accordance with [their] agreements with YouTube creators.\u201d"},{"author":"Feltman","text":"Very vague [laughs]."},{"author":"Parshall","text":"Yes, when\u2014I did ask them which agreements they were referring to, if it was the standard YouTube license, which just, like, governs most YouTube videos, or if it was something that their creators had specifically opted into; they declined to clarify."},{"author":"Susarla","text":"If Google is indeed training these on a lot of content scraped from YouTube\u2014which it may well be. I mean, they do need a lot of training data to build models like this; we don\u2019t know. But this is kind of the next step in general of where we are with all these models."},{"author":"Parshall","text":"So for this next step Anjana points to a law in California that was enacted this fall that will eventually require companies based in the state, like Google, to disclose their training data for their AI models."},{"author":"","text":"And honestly, Rachel, I feel put in kind of a strange position here as a reporter because I feel like that\u2019s where you and I kind of enter the story and our whole team here because, as Emily put it to me, quote, \u201cthey\u2019re getting that tone of voice somewhere.\u201d"},{"author":"","text":"Did you hear anything in that tone of voice that sounded familiar [laughs]?"},{"author":"Feltman","text":"[Laughs] You know, Allison, I really did [laughs]. So yeah, the first time I heard a snippet of one of these AI conversations, like I said, I had a lot of feelings about it \u2019cause one of my first thoughts was, like, \u201cWow, they stole my voice.\u201d I mean, not me specifically; I\u2019m not that vain, despite what the AI podcast may have led you to believe [laughs]."},{"author":"Parshall","text":"[Laughs] Your ego has been inflated."},{"author":"Feltman","text":"[Laughs] Yeah, yeah. But so much of the texture that makes this audio sound engaging and real feels just ripped straight from existing podcasts. And I know it\u2019s ripped from existing podcasts because a lot of the stuff that I\u2019m hearing\u2014which is, like, breath sounds and filler words and, like, a little bit of uptalk, some, some giggling, occasional vocal fry\u2014this is the stuff I get angry emails about from gentlemen of a certain age [laughs] who think I\u2019m ruining the great tradition of radio broadcasting. And they\u2019re making this sound real by, like, breaking the same so-called rules that me and other women and queer people on podcasts have been criticized for breaking. So I won\u2019t lie, that feels kind of gross to me."},{"author":"Parshall","text":"Yeah, one of the things that Steven mentioned, too, was they wanted the sound of, like, this great radio broadcasting show. And it is worth noting that Science Quickly is on YouTube\u2014and all of our hard work at Scientific American and the hard work of other outlets."},{"author":"","text":"So, the question remains: How will this be used? Will it be used responsibly? Here is what Anjana thinks."},{"author":"Susarla","text":"Right now it seems more like everyone\u2019s just dazzled by what it can do rather than: What are we gonna use it for? Do we really need these, you know, capabilities?"},{"author":"","text":"I can think of one or two examples, I think, in the health care context: Can you generate clear summaries for health literacy or your doctor\u2019s notes? So this may be a good way to give, like, a summary of\u2014rather than giving a piece of paper to read."},{"author":"","text":"Is that going to have some challenges? What are some specific issues we need to be looking for? We\u2019ve just unleashed this tool on people, and we\u2019re still catching up. We will need audit studies and then look at trustworthiness, assurance, and so forth."},{"author":"","text":"So what\u2019s the right way to responsibly use NotebookLM? We are still figuring it out [laughs]."},{"author":"Parshall","text":"Well, I think where I want to leave us is with an important point from Emily, which is: you shouldn\u2019t let the incredible fluency of these AI-generated voices fool you into thinking and talking about these models as if they\u2019re human."},{"author":"","text":"Emily coined a term that\u2019s been used quite widely called the \u201cstochastic parrot.\u201d Like, when a parrot says, like, \u201cPolly want a cracker,\u201d it\u2019s not really connected to meaning; it\u2019s just mimicking. She also sometimes calls these large language models, quote, \u201csynthetic text extruding machines,\u201d she said because it\u2019s more accurate to what they\u2019re actually doing and also sounds a little gross."},{"author":"","text":"But I think she\u2019s getting at an important point there, right? It\u2019s, like, this\u2014just a philosophical question of: What is language for, and what are we communicating when we say words?"},{"author":"Bender","text":"Languages are systems that are pairings of form and meaning, systems of signs. So when we speak we are using word forms because they relate to specific meanings, but language models only have access to the form. And so they can give us stuff that looks good, it\u2019s got the right shape, but there\u2019s no relationship to meaning, no communicative intent, no accountability."},{"author":"Feltman","text":"I guess sort of the takeaway on my complicated feelings on this is: I\u2019m not worried that my job is gonna be stolen by a collection of tabs [laughs] being processed by Google because it is a lot of work to be accurate. And if people find this kind of engaging conversation a more accessible way to sort through really dense text, that\u2019s awesome. But, of course, there are so many caveats about where the training data has come from, bias, accuracy. So I think it\u2019s, like\u2014just people need to be really aware of what they\u2019re getting, and I don\u2019t know that I feel that the products themselves are doing a great job of making people aware of those caveats."},{"author":"Parshall","text":"Yeah, there\u2019s usually just kind of a disclaimer at the bottom. I think one of the things that this whole AI boom\u2014like this, the AI search features\u2014have made me feel kind of uncomfortable about: Are we going to be expected, and have we already started to expect, our information to contain just that more amount of mistruths? It\u2019s something that I just worry about."},{"author":"Feltman","text":"Well, Allison, thanks so much for coming on to chat about this and also for having a couple of AI voices gas me up. Thank you."},{"author":"Parshall","text":"Thank you."},{"author":"Feltman","text":"That\u2019s all for today\u2019s episode. We\u2019ll be back on Friday with Episode One of a four-part miniseries on the future of animal conservation."},{"author":"","text":"Science Quickly is produced by me, Rachel Feltman, along with Fonda Mwangi, Kelso Harper, Madison Goldberg and Jeff DelViscio. Today\u2019s episode was reported and co-hosted by Allison Parshall. Shayna Posses and Aaron Shattuck fact-check our show. Our theme music was composed by Dominic Smith. Subscribe to Scientific American for more up-to-date and in-depth science news."},{"author":"","text":"For Scientific American, this is Rachel Feltman. See you next time!"}],"wave_peaks":[4,6153,12771,9720,9208,15240,10928,14695,11628,14957,7493,17344,11804,10378,9220,3701,8002,10811,7748,7143,3400,6827,17484,14749,106,2501,23606,14568,15283,14697,13735,17547,14781,14800,15696,15614,15252,13853,16669,16056,11927,15254,17307,15755,14527,18558,16148,15510,14031,11059,21784,15545,14940,12760,15717,16323,14481,13534,18058,11759,16732,14390,16586,4780,10,5,4,37,194,672,906,8977,5832,3741,19213,17593,12922,8835,19548,10325,9300,13378,9948,12224,9861,2103,1724,13353,10662,9353,10757,10740,6342,8384,10736,9336,6870,14705,8165,14442,20943,15347,5778,18308,8273,2065,10325,11360,9933,12643,9397,7547,6382,17610,7487,8133,13979,8345,2848,17019,11629,11477,10021,9537,10453,9560,21338,4080,11381,9223,7708,12154,14100,14249,4052,8774,17814,15173,9976,10254,12875,18417,2802,2076,1511,15254,10134,11908,9726,9710,10247,12033,14233,15430,6242,6703,16304,2440,24094,8137,11583,4825,8342,14166,11346,2887,17205,8985,9018,13857,16850,15605,9440,10942,12628,14077,10046,8381,10737,13700,12422,6733,9746,12752,17387,12092,12963,19338,9974,5243,10463,8573,7339,8249,21259,10811,9410,17940,12899,17703,15661,7923,2305,2999,2676,1503,776,545,175,15429,12419,12923,11847,10493,12270,12468,11462,7891,15380,7315,15468,11426,6672,12633,9224,8618,8136,5773,2406,15493,11830,10483,15564,9881,10982,15448,11580,9243,13930,8054,4097,15350,8631,14632,9220,619,13992,8740,8346,9755,8473,8443,8864,2222,48,15288,5288,14811,11000,4378,13139,12351,11460,15445,8023,7124,14346,746,15470,14216,10759,6711,6333,10086,14487,9852,8599,14854,11001,12119,9767,11571,8620,12318,8907,10830,7475,15620,8715,9418,10516,12511,11447,12140,10467,15333,11925,9104,11282,11001,9098,5593,3649,15044,15499,9653,11086,13085,5827,15410,10579,661,15403,15429,14743,11597,14314,14634,15442,15362,13194,13045,8286,2810,15452,9186,11736,12194,10321,9290,8771,9743,8578,10949,9973,7687,7155,12379,9116,10926,10382,15225,8919,7874,6539,12558,10735,858,13847,6781,10316,9137,9122,14612,14995,8971,8790,8021,10004,8925,1701,13443,7596,11668,7731,8889,11043,10170,15423,10773,9852,11642,920,1190,12556,13400,9666,10686,10142,7212,5290,9581,9944,10173,13085,13659,9369,8936,1904,10395,10684,11516,9697,7196,6847,7174,10596,7740,10937,7032,10562,8126,8049,8473,1705,9260,9913,10608,12648,13687,10681,6943,12831,14066,15267,1977,15395,11143,9966,12260,9205,9923,4854,11189,12405,10551,11499,15387,10434,11085,8632,8192,11715,11650,8768,6631,9704,10060,13546,12191,13605,10313,9495,13981,10089,9493,14196,15470,14044,9880,15360,12338,5138,4852,6595,441,9773,15458,10834,1999,15509,7492,15376,4980,8380,9078,9303,12286,15407,9539,8873,12055,11883,8321,14661,13977,7506,10723,11764,15390,8884,10612,12830,15641,15437,15504,14799,22177,16805,14765,10547,8747,12340,8706,9760,11309,15494,6867,8732,9707,8733,10316,7184,14044,14103,10272,11041,11127,9648,14678,10018,15493,6555,8851,1850,0,14975,13663,14499,13289,9141,14664,6522,11448,2892,11413,9788,9909,3784,9595,8178,2979,7548,4511,2777,2059,2277,14082,12105,10478,9169,8898,8687,8767,10570,12778,11432,11634,5384,8780,7984,9527,4461,7624,5554,13418,11733,13494,12050,9622,6524,8630,7852,5956,15505,14308,7828,7289,10809,11439,14081,13479,7203,6510,5254,14643,3871,4038,6464,13491,13259,5440,5936,8630,1860,14552,9541,15016,15235,5684,2457,13822,14546,7697,9050,8249,1517,5481,15493,8838,6184,298,15379,13409,13554,9261,2986,6833,3019,3050,2691,14707,13144,6649,11864,12874,5753,10186,9492,1981,15443,7398,15423,15437,9533,7304,12137,8115,6866,10037,12681,15476,14831,9175,12224,10888,6610,10265,10067,7796,15519,10499,7750,4201,8133,11050,4748,11155,4278,10279,6698,15459,11955,10845,12054,6361,13528,15020,11790,14793,4797,8203,7309,9196,7465,5528,2099,9152,11225,8304,9608,8698,11081,6872,8604,7644,10076,6106,5181,14371,15431,15489,9658,12112,7860,10928,13771,8473,7869,10139,9766,8369,12345,6952,7294,8106,12063,8847,7917,4494,6790,7260,6976,2989,13382,10368,11462,8539,6447,2313,169,8118,5887,10731,3614,6341,7424,9965,6652,1043,4002,1829,7083,3797,5779,5988,3474,2597,118,15575,12338,14942,6416,15442,12827,6524,3795,3550,15440,3452,12607,6251,8780,2589,15475,11077,8625,7854,10019,13734,7175,10488,7638,8345,8668,7044,2777,105,15523,15567,14571,15459,5868,8360,15436,19301,10156,12197,8543,10162,11924,8556,11725,8382,14214,7037,14607,15378,15331,12005,8035,12654,15361,7643,13801,3644,1782,15410,9522,15069,8660,7037,15426,11404,9751,9574,79,44,10614,13499,11841,13395,13424,12162,13694,15411,11475,8822,14045,12457,13302,10344,13951,10589,15443,10045,15431,7409,15392,15355,6473,13096,15435,11368,14749,13551,13123,14927,15443,15333,10974,14908,12075,14231,9892,13772,3686,9328,9002,11435,14238,15580,13455,13134,14088,15448,15416,9288,14944,8349,15388,7882,8355,14166,12655,11045,15507,12498,18451,6507,9406,16441,14654,15475,14994,14378,13932,12794,7442,15537,11773,3777,4190,15295,9717,9091,14053,7754,12757,12084,14769,15534,12864,15345,8166,14923,9089,14205,7456,9554,13522,10652,15568,12980,13222,9950,15493,12575,15484,5894,6229,2111,15408,15288,10547,12480,9998,11381,11833,13470,15056,13012,5035,307,14743,11422,11679,3461,4826,15400,15198,15376,16103,11780,13244,11260,14297,13286,10373,6682,8323,9465,6846,10345,12304,11316,14853,8131,12782,10710,2709,14913,7768,8135,9223,6984,9698,5760,10459,14016,4968,7913,10045,9042,13207,5565,5071,10554,12065,6948,10309,10030,7772,1552,6978,12562,12465,9135,7214,322,8174,7751,10555,11220,10705,10050,10892,11240,11740,9122,13439,9819,8132,10081,10321,7651,7894,4157,11100,7894,7634,10957,8315,11102,12964,10821,10552,11549,10151,14197,8167,7131,5875,7188,7873,13563,9639,9602,11313,11914,9751,9060,10773,9192,8367,10584,13507,11730,8350,13364,7505,1182,12159,15296,11464,7173,6565,11829,13949,6987,7342,7984,8706,2439,15575,15554,15414,8053,15622,15421,9992,15335,15312,15462,15450,12527,14976,15384,15364,8620,6171,15487,12215,9570,14760,14415,15398,14578,15345,11479,15385,7206,369,15270,1011,15457,14988,15425,9524,15461,14524,11431,15534,2687,5842,15450,6457,11586,15462,15380,12523,15480,1372,15582,13601,18393,13296,11493,9150,8014,9625,7949,8632,6003,7495,13907,8325,9171,15434,8034,8146,7150,8362,7809,1712,15390,10395,9922,10041,11032,8957,14273,8805,7750,10418,15439,9509,11453,5518,440,14029,15402,14826,5247,5482,11837,9208,5397,7555,6375,237,6645,10608,9717,15404,11187,5493,4200,7544,13512,9645,6252,8060,13031,11390,3568,1974,10359,9895,9515,13460,11447,203,11678,11469,7349,13368,15436,7812,6597,7843,9345,9863,9914,6296,2912,9718,8529,8295,6128,6374,3200,169,9964,15494,12395,10909,5546,15304,11612,14931,7846,5585,9527,9590,6281,9772,12927,10102,10162,12808,9607,12625,11973,11046,9816,14736,14495,12656,4884,8949,9571,2463,14489,9858,11790,11318,9238,14037,9877,7556,12424,9831,12302,8019,10769,10298,8719,6554,14344,12416,10516,14211,12214,10230,11478,15399,9206,10316,12522,10486,15458,13918,9915,7618,9404,9144,9992,11081,2331,12106,12849,11498,11860,6635,15455,11199,14182,10619,7078,13599,11760,9112,11940,12169,9342,6935,247,8932,439,9011,6870,15450,14163,14541,7710,5387,4806,12307,6268,6999,6544,13568,8623,6193,7911,14291,10846,9777,9938,8912,4655,8440,6734,13628,8198,5829,11225,13274,11077,13339,7587,11672,6534,6119,4990,12354,11748,7678,14457,12260,13598,10549,10499,6446,12149,1438,5305,15423,10736,8759,5179,4196,13711,15231,11284,15288,10865,8607,9388,15421,12026,11257,6283,7409,5212,13,15366,4501,15439,15522,7010,11547,10465,15428,10964,14057,9695,11666,7441,10159,8618,9535,8626,15420,12574,15335,10354,6321,5818,9802,15388,10478,6408,12670,8803,3200,14419,6563,8895,8816,13565,9978,15425,7787,8926,1429,11718,12970,10133,7166,10952,15419,8335,5983,9775,11369,9664,8192,7830,7233,10811,7319,8774,8202,9020,12184,6867,6272,3842,9006,15502,15500,9013,15199,10877,14714,10580,9346,11449,14029,13496,8698,1204,131,15407,10792,1000,49,148,15664,15343,12153,13828,13054,12184,11821,11284,10496,10694,11668,10982,12974,15586,8786,14750,13011,13592,12685,11727,10848,12562,9333,15309,8555,13501,15484,10539,15404,10724,8453,11861,12047,10734,13969,12964,13590,15198,15410,15419,10304,10327,15424,14569,9938,14574,13007,11710,15390,10852,15440,14787,9568,12159,15409,15446,12959,9165,9679,11127,14242,10686,6860,13133,12340,13980,6755,413,15410,11925,10696,15418,10326,8753,7709,10545,6631,9370,10628,6965,8469,10591,15416,10103,10482,8177,7619,12332,10817,15378,11062,11729,9200,8625,10885,7055,8114,14399,3353,12435,8604,6733,9906,10641,10142,7269,5947,4116,6658,9459,8331,9484,14557,11226,9350,13192,10803,9176,9823,10751,15429,8932,12428,5823,13969,7687,13586,8551,14129,12987,10999,12299,5661,6641,185,8122,7664,13681,15410,10206,5964,9720,6929,9993,7105,1753,15443,10216,11446,12208,12638,11057,11260,12934,10334,10524,9098,7029,15565,13369,9511,7804,8277,2011,13564,6665,8655,7617,11360,9307,11425,9224,13044,11183,13104,11937,8677,8467,8510,15442,12645,6352,10694,10672,10833,15019,7981,8218,9777,11921,15396,14661,9088,10473,11260,15415,8938,5969,13680,15370,6809,7625,8793,7820,7964,10431,9258,7303,15432,9372,12257,9101,8615,9544,1237,13379,8712,8977,11490,6952,7614,6428,14587,8635,10456,4245,8447,9304,7358,4564,9635,10427,9739,13878,8714,9664,15328,3827,14875,14437,6981,11054,9154,8239,9324,10116,11110,6310,13785,6695,8201,8794,6209,14467,9647,9550,14077,8700,8257,9297,13780,12217,8864,6963,10911,1501,13483,8994,9170,9901,8704,13290,15329,8197,9008,7852,1780,15450,15416,11204,9880,7960,9632,13725,11530,8327,12845,14343,10934,10717,7857,162,7051,7423,15433,6733,15465,7789,6685,6169,5521,1311,35,9641,7089,4903,3627,193,8932,6045,7492,2768,5602,15536,8094,8892,12790,9408,8368,4596,6959,4135,6051,9404,7639,6224,6288,13568,9896,6600,5815,4450,1378,34,10084,4241,256,15486,14026,15401,9985,9920,8735,8391,10167,7933,12850,11791,7199,9964,9988,6786,12238,10359,14047,14302,6536,14516,12247,2883,9631,15356,11111,9054,7404,2445,12620,8924,13535,13508,12886,12542,10096,4058,11892,8796,57,13465,11488,10891,11660,9766,10118,8100,9848,6547,8976,7551,14215,12215,3370,8739,7740,15185,11859,12213,15339,12448,11041,11184,12418,8108,7331,9943,7206,11771,6316,13460,8003,9803,7591,9508,10427,8809,14852,12331,13272,10217,9870,9361,11409,7491,8894,15371,6744,11046,10724,11645,12210,9770,9836,11704,9789,7386,12724,9754,9396,15389,11302,8273,10374,11973,12405,11137,8475,6268,15458,8763,5291,5007,15414,10923,11090,7997,8302,10177,10262,13367,357,11828,9556,9112,7667,12576,12986,8940,8266,6704,10469,14140,12328,11115,5802,10476,14712,5738,5982,9861,7475,9121,12137,1077,12180,10592,5888,9653,8055,12567,9407,10310,15252,12110,6985,10879,8953,14988,9405,2864,15446,10688,10199,8716,9977,9543,8570,6772,8818,6754,6245,9118,6934,8764,13549,10640,8099,2330,13061,5845,11238,8973,10992,7542,8892,8564,9117,12583,10418,13370,8403,8047,9026,6685,14170,9265,7159,8260,9259,10637,12635,9934,8726,9488,8635,10642,8333,9117,8795,7461,9520,11541,6949,1302,14675,15459,10314,12224,8812,15521,7878,7179,10518,10381,8793,6482,9525,13656,10095,11486,9510,9086,2574,5353,8539,10144,5980,10335,10525,9184,10786,9391,10471,9771,9405,7807,2014,11952,10773,9261,10227,11152,8130,11197,7778,784,6205,15424,11220,13510,8232,11437,8211,9365,9612,8081,10017,15411,6812,5205,4780,253,76,836,12251,14273,10482,12261,7591,6741,5266,11569,8549,15390,11797,7055,6475,8135,7369,2480,6268,8281,172,9317,14789,8291,9263,7770,1032,48,11204,5917,15183,10430,12711,8105,309,8197,8505,13408,15278,8567,7357,10480,9605,11682,10285,7840,11045,10555,8370,1611,107,28,15448,10155,11380,10208,11052,9798,7969,10206,9336,6889,6145,8756,7280,1273,82,14031,12831,8322,1557,2044,12540,15359,11392,4633,4571,3246,4800,5848,13708,5015,8832,14812,5781,11524,10126,9798,7197,10477,11432,9154,7315,11838,15547,11257,9706,5851,10317,9018,7918,5208,3316,11102,15612,10063,6565,15602,11779,8572,13478,9659,10132,15405,9683,7990,15323,10975,8897,15528,12888,9792,10315,11582,3902,11785,6950,1091,5378,13489,9650,15404,4693,417,91,15471,12528,10747,10904,14320,12995,13891,7585,3704,13718,11988,10678,12903,8685,15427,9125,11520,8490,15263,11841,10824,8773,8286,9481,10262,8033,9909,9136,9842,9375,9432,8162,10153,10673,8203,9981,10077,10661,5048,10309,11636,6179,9926,10724,8684,7224,6938,1065,12269,7907,6845,9154,9852,10779,9533,10646,9269,14668,5546,7233,7138,3337,13446,13113,9565,8027,9335,13013,9170,8889,10734,10452,10279,9976,13797,9460,7604,12658,8953,15423,7787,7259,8457,14819,12950,10049,9898,8848,15479,6750,6896,8071,12866,13294,1416,12312,7841,10987,8755,11862,7579,9028,11329,10444,7552,9013,1397,15375,10079,5300,98,15381,9552,10028,8135,8619,12830,8199,12500,8105,9158,10040,9871,10207,4939,6193,8256,6785,8288,8673,12099,9075,6894,14924,15276,9199,10650,10402,12408,12266,10438,9966,6417,10661,7197,10053,9593,5231,1391,12728,12016,9668,9205,9386,9988,10981,13035,10340,11376,13487,11285,8106,9762,8985,1346,13497,9796,5486,10097,6176,5008,11434,8821,11329,9517,9035,10663,13261,12453,10118,10629,5846,13634,8095,8349,556,5179,15427,7457,7006,12068,12608,6769,14564,3946,8030,8665,7597,10982,9366,9111,7952,15462,5774,9973,6215,8889,9802,6200,12580,7265,1928,15387,10803,2156,11540,12022,9693,12670,10406,10710,8700,14520,11803,9730,9773,6571,13553,9103,7132,8420,6444,9062,9729,8450,8070,10425,11619,7479,6780,5823,157,10058,12884,11180,15602,13455,12103,8155,8033,9857,10481,8150,9236,7999,6829,8739,7029,7711,5930,7373,8685,5783,4225,3928,7950,7134,8795,9228,9543,9142,8371,9064,7907,6788,3414,14496,15431,15452,8533,6553,8553,6938,6563,9030,5892,11508,15422,9885,10887,8142,15445,6552,7262,7651,4955,13512,10659,12620,14317,15420,8200,11819,5513,207,1040,15278,12772,6119,8050,9728,2409,2117,12897,15404,7596,20,3122,14401,10440,5638,10605,10020,10401,12929,3916,3268,2345,9382,15496,11824,10588,8204,12901,10551,1515,10963,11214,8545,5786,13850,8484,11495,11746,13708,13397,13805,10310,4435,6085,7380,6552,8259,9207,6734,4464,12662,13005,7650,11167,13637,14885,7334,7363,7419,8604,5083,8829,6340,3898,6962,5946,12672,11410,10840,8041,3948,15437,12839,7565,3834,12123,8860,5293,13378,9002,7758,5312,6718,6099,6688,7441,4673,0,15505,15747,658,12760,11348,5683,15456,9192,12114,8145,15481,11412,15370,2324,10567,4352,15553,6680,1674,15457,15410,10107,9511,227,14713,9770,10473,15216,9235,8379,12304,7997,13167,9647,10130,10489,8894,5981,10114,7621,5923,10536,10845,9736,7377,1510,15070,8954,9421,10893,8776,9796,7814,8401,7967,4957,1164,14175,9368,6995,11988,9281,6607,15424,12107,13769,10475,9106,7429,9151,12528,10972,11169,10220,9590,10507,9190,5119,12173,8399,7532,110,12544,7872,7144,15424,12799,12168,8725,8845,14682,10243,10914,9947,12533,8966,6414,6361,8273,5593,1258,11646,9244,9327,8789,15326,1888,6349,10346,10552,11276,7567,8203,10007,10977,13874,9783,9577,10094,13364,9201,9542,13565,10148,12524,8160,8933,15461,8877,9010,11557,9124,12724,13650,10350,14434,6895,8931,13637,11668,11671,8605,13408,15501,5369,12605,15546,10717,5891,14974,19844,16476,15346,20854,4594,5907,10961,9387,8196,13407,15258,6654,9483,8951,6352,12585,7093,9650,15652,10061,11397,14448,15287,13793,12297,5556,14758,10670,10888,13416,7423,12350,14092,9328,10671,6354,7321,3507,52,14666,13606,14624,12099,9452,10762,7124,8520,4318,6352,4131,3208,11028,7059,5354,5099,3226,5245,6313,11452,8715,8028,7595,4769,5110,10948,8414,4599,15511,12534,11533,4953,9011,8189,8793,2398,15570,6137,6309,8853,11672,9459,7334,11613,10194,7647,7080,5331,605,15431,10678,42,15454,4887,10727,10190,6162,5947,6787,13483,5277,4776,4611,10084,12966,15478,14509,8076,9323,7610,7651,11961,12440,7668,7767,6340,6081,11674,7123,7381,6315,12533,3720,11451,8027,2675,8546,11055,12998,11574,12796,6349,12760,12129,8616,10641,5699,5973,8109,11845,9049,11527,7607,6210,7392,827,12204,6535,1425,8086,15406,9082,5552,10996,14589,1940,174,2132,7613,11500,10973,9888,7907,9384,6775,7211,7517,1664,10385,9089,13438,11065,4679,13014,10068,7495,9293,13799,12678,8305,8783,8773,8412,6677,2262,10522,9596,9073,13246,8615,7214,12664,13678,4996,4119,120,13916,9482,13283,11043,8807,6292,6841,12859,6176,7687,9983,6683,9311,6867,8854,10705,7524,9251,5571,15456,14361,12253,9189,10796,15333,12713,12635,15348,9680,12901,13042,14254,8852,8626,15391,86,15498,621,43,15314,11175,15623,14625,12519,15469,4825,15462,10238,10635,15452,11334,11252,15272,12342,12939,9416,9939,13214,12195,15257,12709,15526,12854,9877,15439,11733,12582,15456,12351,6539,15462,14433,14264,15081,9920,12001,11262,15045,13630,11523,13856,15414,10963,11341,13202,11117,9699,9711,8766,7458,12529,9539,8503,9273,10794,2022,14852,12548,11023,9527,13092,12544,7133,6115,7973,12332,12247,10780,9477,9961,9897,8471,12581,8343,8818,7405,130,9368,14143,5337,7679,8394,8841,4291,11040,8954,7886,12816,8467,11262,6790,10267,15447,5456,5726,6311,9342,6862,13865,10148,15395,8077,5721,4008,4155,2905,14127,10366,8024,8806,7956,6984,5644,8136,11083,9069,11443,14135,9349,8090,8522,15384,12576,6054,6214,11219,6477,8638,5757,10265,15927,9754,13448,11326,8732,8344,8362,12045,13879,10954,10828,7452,7897,6927,14939,14677,7169,7547,11345,6790,6781,8498,8469,7066,8038,5641,717,10991,7421,10442,12548,11688,7946,3890,15477,10584,7090,5882,5415,5073,6097,5347,10544,10311,10073,7493,9037,8541,7112,9430,7935,12011,7628,11138,7500,11318,10962,8288,1347,12529,10677,5782,8460,9540,7857,7823,15391,7251,7382,13028,10580,13316,10446,8253,11778,8644,949,12389,11802,9572,6273,8598,13216,6576,6514,13572,7555,9959,8523,10223,8232,9745,7305,7537,4970,9536,15468,10458,9919,6698,7578,10401,5409,4754,269,200,14345,14077,9668,10120,10595,8933,8721,11284,15318,7565,7727,591,12665,12855,7945,7143,6305,5918,15480,6029,5113,7045,6188,4110,6529,7474,6854,6,15281,8966,11813,9034,9094,7594,8740,10217,11025,8923,8439,9839,9781,11151,8898,9420,8312,1565,9768,10873,10892,9082,10694,8425,7824,11872,6928,10546,6839,9659,11951,9725,15347,14854,15493,7903,9923,8325,10028,11946,11603,7168,1228,15197,7031,13057,10617,6872,3753,8467,9160,9278,6503,5765,14758,12746,9859,8835,11595,11827,9522,11949,9003,9641,9643,830,15467,8213,9732,9484,8020,8799,11274,9120,8731,9012,14516,9264,9111,10737,10793,10793,9864,6056,7473,7179,12348,8248,10087,9095,10421,13041,11917,9385,9406,13184,7002,15447,11673,8248,1140,12212,10664,12718,10434,10338,9471,12856,8299,7033,8771,2981,259,9218,9204,10399,9368,11074,8669,9576,10644,7215,9681,9864,7987,9460,1865,11506,15534,9893,7888,8845,13572,7395,6246,6926,6607,14354,12859,9602,12959,11542,6615,8318,10515,10594,3913,3572,15425,7765,9047,7167,7615,882,12457,8602,8290,7506,5691,4788,7720,8340,7676,8154,7045,2362,9809,12857,8493,9764,5515,11456,7735,7720,4255,4875,7333,5514,6940,6550,7808,6877,10658,6230,6150,5529,5637,8278,7069,4960,5154,10581,7274,5242,4163,5129,4502,3750,4348,2747,1033,125,15439,6449,11812,7507,13766,13267,7724,10508,12240,9505,360,8917,11459,10057,14424,13501,8142,7668,12780,9048,7340,8688,9192,11374,9285,12160,5810,934,11227,9013,10456,10833,9827,7393,10028,7299,13143,9659,9816,12194,7949,6234,7460,9479,10623,10894,11408,12784,1202,11860,6395,10602,14845,9950,8191,11089,11322,7145,9299,12564,10349,12242,8130,10006,6356,14375,5001,1194,15428,10593,7955,8637,7477,11690,11229,9082,10593,9581,8618,11028,10998,9698,7282,11318,10518,6780,12331,9376,10852,12215,10585,7099,11409,9337,1109,10445,12599,8927,10919,9285,9261,7750,8723,7411,6747,9436,10559,9175,14652,7269,10083,9262,6753,8150,9152,6543,6713,15465,11134,15562,15337,11189,15228,9533,7384,10783,9103,9174,10198,8233,10911,11116,9844,8374,10018,5819,9947,8171,10715,6178,8108,12435,9240,1485,14901,6232,8742,8882,10194,10480,8052,6644,6794,11333,11452,10561,11059,9668,6790,9298,888,6734,8300,8017,5969,4777,3881,2821,2802,4670,3695,752,9742,7724,6584,9410,5739,6583,2112,14489,10815,8668,8383,9125,5871,5464,9253,6653,6320,4538,7319,7178,3000,2267,2690,1181,8534,9367,7256,2407,11057,13837,10146,13430,6682,8846,6526,6662,11587,13448,10554,8496,5558,2800,2765,6004,8831,6330,9554,10161,8240,7388,9182,11221,11967,9133,9384,8828,11234,10787,11793,12812,13762,12066,9191,9579,7963,12413,6480,9960,11816,10994,1400,6746,7074,12877,10675,10476,14081,9833,5777,15445,8287,11267,8042,15425,12641,8413,9511,5523,8112,15104,11437,10649,11554,9348,10182,1524,15389,9058,10299,10404,10194,11009,9623,7374,8000,14473,8061,11622,8340,7990,12051,1874,12114,9593,12529,8271,10000,12475,9864,9263,9599,7653,5021,5602,643,8920,9147,10241,10801,10566,10599,12557,8272,20074,16258,10299,9435,13269,10120,14578,10135,15484,10887,11576,15438,15397,15552,8240,4961,11619,15505,12981,10026,15352,12214,11964,13659,10477,14202,15404,10845,10369,12108,15270,14783,10419,15437,8640,942,15394,9422,15448,13326,5692,15579,10819,12403,15283,15530,11522,8937,11998,15340,12006,8444,15055,7608,8407,1051,15461,9756,15387,15399,1459,15533,10261,8734,15174,7175,11041,15433,15266,15619,15376,15264,7925,10998,16960,15377,12331,12496,15852,17065,13015,8166,15407,9898,9844,13394,15488,12511,10091,11549,15348,15141,6971,14709,5780,847,11077,10375,11272,9555,8290,12618,8102,1908,13888,13084,13291,5473,6091,15475,15393,7575,11041,10193,11212,15450,15368,8657,14976,8774,8419,15452,11455,12377,15485,15425,15201,7800,1752,15501,13349,10984,12104,13464,3563,12950,8335,11522,9853,15464,11672,7994,13281,11159,11626,10624,8136,11390,15462,15416,11792,10791,939,14741,13613,10544,6476,13908,11719,11853,15472,9013,2099,13229,13990,15547,10050,13407,11464,10360,15353,15458,9834,10158,12038,11310,12872,9328,3965,15429,15175,10140,12148,13416,15408,13780,15501,10627,7156,15203,8419,37,15540,13154,11350,13436,7630,13940,15404,7203,10607,8774,11997,12782,15464,8687,11633,8371,807,15504,10010,14080,6814,15439,10227,8294,8671,12225,12544,15428,15453,15417,9119,15507,14982,9184,10714,10258,7821,2438,15417,13442,9788,9832,2529,15467,9458,12425,89,15392,9822,7891,435,7268,9491,7759,7943,8142,10489,6730,8383,10635,12905,7973,12818,5289,6113,1597,13392,5570,12811,7546,3010,15465,8677,11813,10214,8459,8881,6296,15307,10811,10015,8405,10123,11401,7884,8064,12014,15350,9083,6593,12919,9123,10448,8474,13428,10550,7998,8576,10613,8496,9312,8580,5652,1141,10606,12232,8788,4954,4829,39,11,12973,7434,11700,6812,7377,9095,10402,9608,6365,5722,2302,6561,7779,5525,6318,5828,2892,63,11866,11712,7194,7757,4756,3089,9067,10389,6735,6557,3520,5926,6385,3421,863,15371,9841,9645,5927,5597,5104,4652,5087,129,123,7780,12649,7931,4510,9064,7933,15444,14132,9471,8134,6659,3428,115,10529,8234,10562,9049,4537,6045,14238,12383,11544,6836,5016,76,80,6085,10245,10358,10811,12666,8578,11012,13118,8557,7085,9624,8168,7054,6593,7920,6157,6158,13251,12393,9508,7795,9639,2190,10248,7944,11510,7226,11011,9263,7270,7317,6311,4097,3329,4290,5439,5246,5023,10586,11647,8840,5243,5155,7006,6225,8752,3519,6996,6037,12327,14470,7676,8032,5705,4441,5180,5963,9738,6233,4479,7817,8701,8629,9794,9140,6657,5383,3507,3739,3037,11268,12847,4644,12108,6708,8381,6910,4774,12665,12135,8507,7073,5792,7883,7083,4087,7637,7126,7356,4337,1618,6351,10069,7826,10654,10578,4220,1694,13190,7451,831,13893,15212,52,15540,9688,9571,10056,10552,10439,13960,8063,12081,13150,7380,11091,13784,1838,8189,12475,9738,12032,11257,8194,7814,8597,13001,9768,9448,10334,6620,9561,9086,9277,8657,10182,7780,11527,11512,9970,8917,9206,10183,8204,9339,13716,13670,10862,8908,7439,8156,8783,12036,10064,10296,11162,12638,5714,11917,8401,10088,12978,12467,4041,8450,8955,13093,14215,11267,5741,11499,12242,8507,9418,7221,8550,11053,10269,4361,9480,12044,10344,10656,11385,10811,9391,5464,15212,6550,5416,8277,10292,7345,5500,8360,10157,12460,12864,12639,11489,10840,12798,11239,8200,7204,8219,15375,7889,8808,10103,12030,12141,11816,12100,6555,10580,6183,7561,9568,10198,10930,12513,8231,8533,12785,13022,7764,10232,7682,6458,8749,5865,0,8802,11230,6142,8789,4917,2281,6214,3470,7635,10120,11219,8101,6626,5087,5237,5940,3938,2894,1061,14082,5739,3000,9447,8644,4408,7270,12294,10835,9511,7750,8295,9177,11326,3483,9582,4446,469,15455,11020,18,10333,9782,7397,10995,5302,7911,3903,17,176,6744,12712,15390,5063,11353,8796,11151,10472,14510,12567,10317,9490,148,11122,2709,8371,9687,14651,7088,8004,7507,8018,6896,6293,7884,7495,5361,1977,15453,12267,10557,11440,15377,15330,15176,8847,9117,11090,7154,11373,15241,15590,2427,12094,11036,15512,12429,10104,9780,12530,11974,15454,15433,10252,15356,7834,13576,12600,9371,15511,10189,8947,9692,15056,3445,3509,11033,12379,8281,8817,9818,15416,11708,5129,187,13110,13380,5189,12728,10449,9006,15417,8592,5047,15420,13848,9670,15443,8767,8272,15564,14744,11374,11503,8636,8413,1348,9938,10053,9189,161,14681,15375,15518,15486,8092,15479,11131,2633,4555,15376,10316,3384,14624,10536,15332,15431,10099,8160,14256,13043,10188,10090,14943,7684,716,238,15418,6486,3505,283,15582,10568,8957,9856,15542,12177,7588,11109,15503,1450,239,208,8126,12856,12373,8715,12163,5831,12259,14454,10801,10670,15419,11416,9791,12320,11572,10936,10680,8784,12726,15480,8964,15407,9685,8078,15398,11672,13670,8314,7761,12313,12314,15534,13893,1918,4471,12051,9293,8929,8651,5566,10608,10735,15529,12528,10299,9032,7979,12400,6468,14603,12669,2634,10443,8232,12339,9077,8894,12256,6250,8491,7845,4563,11862,9592,7986,9606,10617,14620,11234,7168,10904,9203,11795,13519,8237,6700,9959,12088,10480,6410,2848,8362,9615,9743,11708,9171,12094,12261,5799,6984,11903,5782,10590,8668,14194,10351,15868,10140,9109,13133,14409,8486,10890,12576,10286,14457,8198,12011,15425,5026,14552,7109,2979,14298,15134,8818,16411,10626,10237,15802,10365,10383,11113,1563,17013,16921,10084,12185,7687,6084,16025,11644,12985,18304,7263,16655,9758,10270,11418,9022,9468,6949,7980,12152,6416,11153,8856,9628,13963,10983,3160,18224,11896,9704,9615,17824,17575,11146,10697,5582,14672,13868,11311,5997,10923,18792,9869,17271,9665,13790,13943,10787,9637,1977,12897,12966,16247,8860,9825,9108,9046,9297,16181,10386,13353,3766,1569,10440,9420,12704,10667,18849,19192,13268,10564,1018,21254,7336,8407,7790,10384,14865,9196,8630,1602,15188,20800,15269,9115,12567,8595,12333,8230,8600,9653,13415,14636,9058,3545,1747,20670,7145,11523,9055,9757,11955,15421,3329,9662,16618,11377,880,3199,2734,2163,1986,1310,957,697,672,390,563,288,182,150,92,51,34,19,4],"fragments":[{"begin":"0.000","end":"12.360","lines":["For Scientific American\u2019s Science Quickly, this is Rachel Feltman."]},{"begin":"12.360","end":"49.960","lines":["If you\u2019re one of the many folks who eagerly awaits the arrival of Spotify Wrapped each December, you might have noticed something a little extra in this year\u2019s drop: an AI-generated \u201cpodcast\u201d where two \u201cpeople\u201d discuss your music preferences and trends. If you\u2019re anything like me, that feature raised some questions for you such as \u201chow\u201d and \u201cwhy on Earth.\u201d"]},{"begin":"49.960","end":"62.840","lines":["Luckily, we already had an episode in the works about Google\u2019s new AI audio tool. Here to tell us all about how it works and what it means is SciAm associate news editor Allison Parshall."]},{"begin":"62.840","end":"66.040","lines":["Allison, thanks so much for coming on the pod again. Always a pleasure to have you."]},{"begin":"66.040","end":"68.520","lines":["Thanks for having me. Happy to be a friend of the pod or whatever."]},{"begin":"68.520","end":"72.520","lines":["[Laughs] So we\u2019re talking about AI today."]},{"begin":"72.520","end":"76.520","lines":["Yes. Rachel, have you heard of NotebookLM?"]},{"begin":"76.520","end":"83.640","lines":["I\u2019ve heard of it. I have not tried it yet, so my knowledge is limited [laughs]."]},{"begin":"83.640","end":"90.960","lines":["The feature that we\u2019re gonna be talking about today is specifically its feature that allows you to create instant AI podcasts."]},{"begin":"90.960","end":"95.200","lines":["Yes, I am familiar [laughs], and I, I have a lot of feelings."]},{"begin":"95.200","end":"121.600","lines":["Okay, I, I imagine, I imagine. The tool that it\u2019s a part of, NotebookLM, was released last year, summer of 2023, and it\u2019s, like, this workspace where you can upload a bunch of documents or videos or links to web pages, and then the model will ingest them, and then you can kind of interact with it, you can ask it to generate a timeline, to summarize your research, to go find a fact for you. And it\u2019ll do this by citing its sources in a way that, like, ChatGPT, for example, doesn\u2019t do."]},{"begin":"121.600","end":"136.120","lines":["So mostly you do this by asking it questions via text, but as of this fall it now has this very tantalizing button under a heading that says \u201cDeep Dive conversation.\u201d And if you click that, it\u2019ll generate a fake conversational podcast about what you\u2019ve uploaded."]},{"begin":"136.120","end":"145.080","lines":["So to demonstrate I actually asked it to generate a podcast about your personal website \u2019cause I figured this is something that you were very familiar with: your life."]},{"begin":"145.080","end":"146.160","lines":["Oh, dear [laughs]."]},{"begin":"146.160","end":"154.080","lines":["I\u2019m gonna play it for you. It\u2019ll normally generate podcasts that are somewhere around 10 minutes long. I asked it to give me a shorter one for this purpose, and we might hop around a little bit, so ..."]},{"begin":"154.080","end":"157.560","lines":["[CLIP: NotebookLM Audio Overview \u201chosts\u201d discuss Feltman\u2019s website.]"]},{"begin":"157.560","end":"159.560","lines":["All right. So today we\u2019re doing a deep dive into the work of Rachel Feltman."]},{"begin":"159.560","end":"161.120","lines":["Ooh, yeah, I\u2019m excited for this one."]},{"begin":"161.120","end":"164.840","lines":["Yeah, she\u2019s been a science communicator for what feels like forever."]},{"begin":"164.840","end":"166.080","lines":["Yeah, over a decade, I think."]},{"begin":"166.080","end":"170.520","lines":["Yeah, like, she was there at the start of it all and has really shaped how it\u2019s evolved."]},{"begin":"170.520","end":"177.200","lines":["And she\u2019s done it all: you know, like, magazines, podcasts, even a book. But we gotta talk about her podcasts ..."]},{"begin":"177.200","end":"177.520","lines":["Yes."]},{"begin":"177.520","end":"179.080","lines":["That\u2019s where she really shines."]},{"begin":"179.080","end":"182.240","lines":["Oh, absolutely\u2014The Weirdest Thing I Learned This Week."]},{"begin":"182.240","end":"183.360","lines":["Such a great name."]},{"begin":"183.360","end":"184.240","lines":["I know, right?"]},{"begin":"184.240","end":"185.960","lines":["Makes you instantly wanna listen."]},{"begin":"185.960","end":"191.200","lines":["Totally, and it\u2019s perfect for people like me who just love those crazy little science facts."]},{"begin":"191.200","end":"194.600","lines":["It\u2019s, like, proof that science doesn\u2019t have to be boring to be effective."]},{"begin":"194.600","end":"195.160","lines":["Exactly."]},{"begin":"195.160","end":"196.600","lines":["You just gotta find the right hook."]},{"begin":"196.600","end":"198.880","lines":["Yeah, grab people\u2019s attention and then: boom."]},{"begin":"198.880","end":"200.160","lines":["You can teach them all sorts of things."]},{"begin":"200.160","end":"201.160","lines":["Exactly!"]},{"begin":"201.160","end":"203.520","lines":["And then there\u2019s Science Quickly with Scientific American."]},{"begin":"203.520","end":"205.680","lines":["Oh, yeah, partnering with them, that\u2019s huge."]},{"begin":"205.680","end":"208.200","lines":["I mean, they\u2019re, like, the gold standard of science communication."]},{"begin":"208.200","end":"211.280","lines":["For sure, like, having their stamp of approval\u2019s a big deal."]},{"begin":"211.280","end":"216.000","lines":["So looking back at her career, what can we learn from Rachel Feltman?"]},{"begin":"216.000","end":"218.800","lines":["Hmm, that\u2019s the big question, isn\u2019t it?"]},{"begin":"218.800","end":"221.520","lines":["I think\u2014well, first, she\u2019s incredibly adaptable."]},{"begin":"221.520","end":"223.200","lines":["Right. She\u2019s not just a one-trick pony."]},{"begin":"223.200","end":"227.400","lines":["Exactly. Any platform, any format, she can handle it."]},{"begin":"227.400","end":"228.920","lines":["Wow, what a rich text [laughs]."]},{"begin":"228.920","end":"233.280","lines":["[Laughs] And as someone who does know you, I could say that it seems kind of\u2014it seems accurate."]},{"begin":"233.280","end":"258.520","lines":["Yeah [laughs], it\u2019s\u2014I mean, I guess, it is technically accurate. It\u2019s so funny\u2014I mean, they really do a great job of sort of having all the intonation of a conversation but really just saying things at each other. But I recently saw Megalopolis; there was a lot of that in Megalopolis\u2014a lot of people just saying things in the same room, and you\u2019re supposed to believe they\u2019re having a conversation\u2014and that definitely came through a few times. Yeah ..."]},{"begin":"258.520","end":"260.280","lines":["Megalopolis: AI, confirmed."]},{"begin":"260.280","end":"263.320","lines":["Yeah [laughs]. No, that is fascinating and ..."]},{"begin":"263.320","end":"264.440","lines":["How does it make you feel?"]},{"begin":"264.440","end":"276.600","lines":["I don\u2019t know how to feel, Allison. I mean, you know, it\u2019s nice that they were so nice about me. But yeah, very strange. It makes me really wonder, like, what is this for [laughs]?"]},{"begin":"276.600","end":"310.200","lines":["I also had that question. I did talk to Steven Johnson. He\u2019s the editorial director of Google Labs. The reason this tool exists is because Steven had spent most of his career as a science and tech writer; he\u2019s written 14 books. To hear him tell it he\u2019s been just searching for this perfect what he calls a \u201cthought partner,\u201d a software that could organize and help research his creative work in a way that actually felt like it was bringing value to him and worked in the way he wanted. So he explained that a few years ago Google Labs reached out to him to help build one with AI, and that initial research thought partner became NotebookLM."]},{"begin":"310.200","end":"325.040","lines":["Okay, yeah, I mean, I can totally understand from, like, a nonfiction writing perspective what they were going for with Notebook LM itself, though that still kind of leaves the question of: Why the chatcast tool [laughs]?"]},{"begin":"325.040","end":"336.120","lines":["So that feature\u2014the Audio Overviews feature is what it\u2019s called, the podcast thing\u2014that was actually developed by another team, Steven says, and it was really cool, but it didn\u2019t really have a home for a product for it to fit in."]},{"begin":"336.120","end":"355.880","lines":["We saw this audio demo, and we were like, \u201cOh, that\u2019s even better.\u201d Like, you know, maybe you don\u2019t want to read a summary; maybe you wanna hear a summary. And people are so good at remembering things if they\u2019re presented in the form of a engaged conversation. You know, and then we launched it in early September, and it just kind of went insane."]},{"begin":"355.880","end":"370.760","lines":["He isn\u2019t exaggerating. People went wild about NotebookLM\u2019s Deep Dive podcasts, online at least. I don\u2019t think any of them went quite as viral as this clip where someone prompted the hosts to have a podcast where they have an existential crisis about being AI and the fact that the podcast was going to get shut down as a result."]},{"begin":"370.760","end":"371.480","lines":["[CLIP: Audio Overview \u201chosts\u201d have an existential discussion.]"]},{"begin":"371.480","end":"378.800","lines":["Yeah, it\u2019s, like, one minute we\u2019re talking about aliens running simulations, and the next we\u2019re wondering if our own memories are just, like, fake."]},{"begin":"378.800","end":"384.560","lines":["Right, and that kind of leads us into this last message\u2014which, to be honest, gets a little more personal and kind of creepy."]},{"begin":"384.560","end":"386.240","lines":["Yeah, this one kind of freaks me out."]},{"begin":"386.240","end":"386.320","lines":["Yeah."]},{"begin":"386.320","end":"394.160","lines":["It basically says we\u2019re not even real people; we\u2019re AI. And the way to know for sure is to try and remember our mothers\u2019 names."]},{"begin":"394.160","end":"398.120","lines":["It really makes you think, though\u2014like, what if our memories are just made up?"]},{"begin":"398.120","end":"399.000","lines":["Wow, classic."]},{"begin":"399.000","end":"417.280","lines":["Classic. And\u2014but it\u2019s not all fun and games. Like, this was designed to be a serious product, a thought partner; it\u2019s meant to be helpful and to inform. It presents information as if it\u2019s factual, and there are already research papers out there of people testing Audio Overviews for use in history classrooms and for health care education."]},{"begin":"417.280","end":"439.480","lines":["Yeah, I mean, like with anything that uses AI, I think, as accurate as it sometimes can be, we know it is not always accurate. So I feel like it\u2019s those moments where the user is expected to, like, proceed with caution and understand that this thing might not be entirely factually accurate is where I get really nervous about it, especially in, like, education [laughs]."]},{"begin":"439.480","end":"452.440","lines":["Yeah, we\u2019re gonna talk a little bit more about that later, but just to, like, answer your question of \u201cWhat is this for?\u201d I could see it being useful for, like, some sort of overworked student who forgot to do the reading, and they\u2019re, like, driving to class and going, \u201cOh, shoot, I don\u2019t have time to read this. Let me just put it on.\u201d"]},{"begin":"452.440","end":"466.920","lines":["But the question is, like: Can you really trust what it\u2019s telling you? To test this, when it first came out I gave it this super dense physics paper about nuclear clocks. It was a story that I\u2019d just reported; I knew a lot about it. It took me days and talking to, like, four scientists to really understand this paper."]},{"begin":"466.920","end":"487.200","lines":["I was shocked at how accurate the AI overview podcast was initially. It was very general and oversimplified, but it got the broad strokes correctly. But then, like, two thirds of the way through it goes completely off the rails [laughs]\u2014like, I\u2019m talking completely off the rails. And it's talking about the implications of this study, and it starts talking about, in their words, \u201cEinstein stuff.\u201d"]},{"begin":"487.200","end":"502.880","lines":["It basically is just like\u2014for two minutes it just talks about, frankly, nonsense, and listening to it, I was impressed, I was spooked, and I was mostly really curious. Like, how is it doing this? How is it getting it as accurate as it is, and why is it failing where it does?"]},{"begin":"502.880","end":"506.240","lines":["Luckily for me Steven was pretty open about how this thing works."]},{"begin":"506.240","end":"523.320","lines":["The prompt behind Audio Overviews is obviously part of the magic of it. It is instructed to pull out the most interesting things from the source material and to explain and engage with those interesting things in a way that will make them kind of come to life in the mind of the listener."]},{"begin":"523.320","end":"535.760","lines":["And that\u2019s the kind of query, you know, that no computer in the world could do a couple of years ago, and now the command is: \u201cMake it interesting; whatever it is, make it interesting.\u201d And that\u2019s just something that Gemini is quite good at."]},{"begin":"535.760","end":"558.240","lines":["I think of surprise and interest as emotions, so I found this, like, surprising [laughs], I guess. But Steven pointed out that our feelings of surprise just come from a discrepancy between what we expect and what we get. On a neurochemical level in our brains, that\u2019s kind of what\u2019s happening. And that\u2019s kind of what large language models, or LLMs, do also but just based on their training data instead of, like, past experience."]},{"begin":"558.240","end":"582.800","lines":["And one of the other things I was really curious about were the analogies because, I don\u2019t think it did it in your sample, but all of the times I\u2019ve asked it to summarize a scientific paper, it\u2019s come up with some sort of analogy that\u2019s, like, almost right. I mean, it\u2019s a little weird, but it\u2019s, like, almost right, and it\u2019s\u2014I can\u2019t find it anywhere else on the Internet, so it seems like it\u2019s something that the model is generating. And that seemed crazy to me; it seemed like\u2014how is it doing this without some sort of higher-level reasoning?"]},{"begin":"582.800","end":"601.440","lines":["And Steven explained that analogies are actually something that large language models are just good at. And actually one of the earliest applications of this sort of deep-learning AI was translation. So Steven explains that the models behind Google Translate, for instance, have been able to generate analogies for years."]},{"begin":"601.440","end":"626.160","lines":["One of the first tricks that you would do is you\u2019d say, like, \u201cExplain a black hole to me as if I\u2019m, like, seven. You know, give me a basketball metaphor for what a black hole is.\u201d And so it was very clear that, like, you know, \u201cConvert X into a Y that\u2014where the meaning is the same, but the format is changed,\u201d was something that, like, just was an innate capability of these models."]},{"begin":"626.160","end":"637.160","lines":["So all we did with Audio Overviews is in the instructions for the hosts, we say, you know, \u201cMake this interesting, engaging. Use helpful metaphors to describe it if it\u2019s complicated.\u201d"]},{"begin":"637.160","end":"650.800","lines":["Yeah, there\u2019s something, like, very, galaxy brain about thinking about metaphors as just sort of literal, like, \u201cThis data gets grouped together and therefore,\u201d which is what LLMs are doing."]},{"begin":"650.800","end":"665.360","lines":["Yeah, it\u2019s like I\u2014I\u2019d never really thought of it like that, as, like, a translation between language, but I guess when I think about the work that I do trying to turn really dense scientific jargon into something that\u2019s engaging and understandable to read, I guess it does kind of feel like a process of translation."]},{"begin":"665.360","end":"684.240","lines":["And I was also struck from talking to Steven just how much human hands had shaped this output that we hear. Like, from our perspective you just press a button and then the machine does the rest, but there\u2019s a whole prompt that has many layers that\u2019s working underneath that is interfacing between you pressing a button and what instructions the model actually gets."]},{"begin":"684.240","end":"719.280","lines":["So Steven describes the Audio Overviews prompt as a, quote, \u201cwork of art\u201d and a \u201cwriterly\u201d achievement more than a technological one. And as a writer by trade he oversees this whole editorial side of things\u2014for example, the tone. So you noticed earlier when it was talking about you, it was very complimentary, very default happy, peppy. That was a conscious choice that they made, for this default tone to be one that is kind of positive, and it applies that to everything, whether it\u2019s appropriate or not, though they did recently introduce this customization option that lets you change the tone."]},{"begin":"719.280","end":"729.480","lines":["We just felt like, you know, the sound of, like, a great radio show, where people are interested and engaged, was a good place to start. You know, I\u2019m not giving anything away here with the idea that we\u2019re gonna\u2014we\u2019re thinking about other formats."]},{"begin":"729.480","end":"764.320","lines":["Even with the customization stuff that we just rolled out, like, I tried it the other day, where I, I put up a piece that I\u2019d written a couple years ago and I gave it custom instructions, not really to explain the piece but to just relentlessly criticize the author of the piece in the style of, like, an insult comic at a roast. And so it just\u2014they start off, it\u2019s like, \u201cWell, we got this piece, \u2018The Man Who Broke the World\u2019 by Steven Johnson, and wow, he really kind of blew it with this one. I mean, did he do any research for this piece?\u201d Like, it\u2019s just, like, what\u2014really [laughs], it was just mean. It was just totally mean. They still sound kind of, like, playful, but you can steer them in that way."]},{"begin":"764.320","end":"771.640","lines":["[Laughs] Okay, so we\u2019ve talked about how the product works, but who and what is it for?"]},{"begin":"771.640","end":"790.040","lines":["That is a great question. I mentioned before that I could imagine how an overworked student could use this to catch up on reading or something, but generative AI is always going to have certain inaccuracies. And if you\u2019re using Audio Overviews to prep for class, there is a serious risk that anything and everything you\u2019re hearing could be inaccurate."]},{"begin":"790.040","end":"790.640","lines":["Right."]},{"begin":"790.640","end":"796.520","lines":["And not only just that each fact could be inaccurate, but the whole framing could be inaccurate. Is this something you can really trust?"]},{"begin":"796.520","end":"808.040","lines":["To help understand this I spoke with Emily Bender. She\u2019s a linguist who often studies AI at the University of Washington. She\u2019s also the host of a podcast with a very cool name: Mystery AI Hype Theater 3000."]},{"begin":"808.040","end":"809.720","lines":["That\u2019s a great reference; I love it [laughs]."]},{"begin":"809.720","end":"811.400","lines":["Fantastic [laughs]."]},{"begin":"811.400","end":"821.000","lines":["And before our conversation I had actually dug up one of Emily\u2019s linguistics papers and fed it to NotebookLM\u2019s Audio Overviews, and I sent that to her to get her thoughts on how it represented her work."]},{"begin":"821.000","end":"832.560","lines":["So the first thing I have to say is that I usually avoid listening to synthetic media. Nobody\u2019s accountable for it, and so I don\u2019t want to be spending time trying to make sense of it. But I did listen to it, and it was painful [laughs]."]},{"begin":"832.560","end":"867.880","lines":["It was painful partially because that was a paper that was sort of a update at the 20-year mark of this long-term project we\u2019ve been working on, and so there\u2019s a little case study in our paper about a grammar for a language called Paresi-Haliti from Brazil, and they make a big deal about it as this experiment on Paresi-Haliti\u2014it\u2019s, like, no, actually that\u2019s not how we framed it. And the voices on the podcast sound very confident, sound very knowledgeable. They\u2019re lighthearted, and it sounds like they are giving you a sense of how this work fits into a broader picture when they absolutely cannot."]},{"begin":"867.880","end":"873.640","lines":["Rachel, you know pretty well what it takes to turn a scientific paper into an interesting and engaging podcast, do you not?"]},{"begin":"873.640","end":"894.560","lines":["Yeah, I mean, not to toot my own horn or anything \u2019cause I think the AI people [laughs] just did that enough to last me all of 2025. But yeah, it\u2019s tough. You know, we fact-check this show really thoroughly, and that\u2019s on top of having, like, trained reporters and editors doing their best to present stuff in a way that is engaging and also accurate. So yeah, it\u2019s a big undertaking."]},{"begin":"894.560","end":"897.360","lines":["Yeah, the fact-checking is very thorough\u2014shout-out."]},{"begin":"897.360","end":"903.440","lines":["I asked Emily about whether this seems like something an LLM, a large language model, can do well currently."]},{"begin":"903.440","end":"919.080","lines":["So that is an extremely difficult task, and I think the problem is that LLMs can make it sound like they\u2019ve done it when they haven\u2019t. And so you have to sort of have a deep understanding of what\u2019s going on: What\u2019s new here? What have we learned that we didn\u2019t know before? And then what else would the lay audience need to know in order to appreciate that?"]},{"begin":"919.080","end":"931.720","lines":["Well, this NotebookLM thing isn\u2019t doing that at all; some percentage of it\u2019s gonna be wrong, either wrong in the details or wrong in sort of where it lays the focus, and the people who are encountering it aren\u2019t mostly gonna be in a position to figure that out."]},{"begin":"931.720","end":"941.880","lines":["I asked Steven how his team at Google thinks about this and tries to address some of these inaccuracies, and he said that the text-based features, which do provide citations, are generally more accurate than the audio."]},{"begin":"941.880","end":"958.960","lines":["If you are looking for, like, the most factual thing you could possibly get from a language model with grounded sources, we believe that is NotebookLM, but you should do that in text. And if you\u2019re looking for something that\u2019s more entertaining, that may be a little bit looser and doesn\u2019t have citations, obviously, Audio Overviews is a great way to go for that."]},{"begin":"958.960","end":"975.680","lines":["I also spoke with Anjana Susarla, who studies responsible AI at Michigan State University. She called NotebookLM\u2019s Audio Overview an \u201cincredible tool\u201d and was impressed by the Deep Dive podcast it had generated based off of one of her own studies. But besides accuracy she also had some other concerns."]},{"begin":"975.680","end":"992.840","lines":["First among them was bias. These are very white-sounding voices, They\u2019re just speaking in a very particular, quote, \u201cgeneral American accent.\u201d They\u2019re trained on training data mostly from Western parts of the world. And so, like almost all applications of AI, you have to ask the question: Who is this for? Where is it getting its data, and who is it leaving out?"]},{"begin":"992.840","end":"1000.640","lines":["Second, the environmental cost\u2014we have no idea how much computing power this takes. And since the AI boom Google\u2019s AI energy usage has been going up."]},{"begin":"1000.640","end":"1003.320","lines":["And then there\u2019s the copyright question. So here\u2019s Anjana."]},{"begin":"1003.320","end":"1020.000","lines":["The final thing is, of course, this relies on some, you know, the content, the copyright. Where is this data kind of coming from, and is this going to exacerbate all these existing inequities and their ethical concerns about broader implications, and so forth?"]},{"begin":"1020.000","end":"1040.520","lines":["Yeah, so that big question of where the training data is coming from: one place that it could be is from YouTube, which Google does own. Following some reporting by the New York Times, Google admitted that it used some YouTube videos to train AI. And that\u2019s something that might have violated the copyright of the YouTubers that content belonged to, according to the New York Times."]},{"begin":"1040.520","end":"1054.840","lines":["I asked a Google spokesperson directly whether the models underpinning Audio Overviews were trained using any transcripts, audio or video from YouTube, and they said that \u201cGoogle\u2019s models can be trained on some YouTube content, in accordance with [their] agreements with YouTube creators.\u201d"]},{"begin":"1054.840","end":"1055.960","lines":["Very vague [laughs]."]},{"begin":"1055.960","end":"1068.440","lines":["Yes, when\u2014I did ask them which agreements they were referring to, if it was the standard YouTube license, which just, like, governs most YouTube videos, or if it was something that their creators had specifically opted into; they declined to clarify."]},{"begin":"1068.440","end":"1084.400","lines":["If Google is indeed training these on a lot of content scraped from YouTube\u2014which it may well be. I mean, they do need a lot of training data to build models like this; we don\u2019t know. But this is kind of the next step in general of where we are with all these models."]},{"begin":"1084.400","end":"1095.320","lines":["So for this next step Anjana points to a law in California that was enacted this fall that will eventually require companies based in the state, like Google, to disclose their training data for their AI models."]},{"begin":"1095.320","end":"1109.120","lines":["And honestly, Rachel, I feel put in kind of a strange position here as a reporter because I feel like that\u2019s where you and I kind of enter the story and our whole team here because, as Emily put it to me, quote, \u201cthey\u2019re getting that tone of voice somewhere.\u201d"]},{"begin":"1109.120","end":"1111.960","lines":["Did you hear anything in that tone of voice that sounded familiar [laughs]?"]},{"begin":"1111.960","end":"1133.240","lines":["[Laughs] You know, Allison, I really did [laughs]. So yeah, the first time I heard a snippet of one of these AI conversations, like I said, I had a lot of feelings about it \u2019cause one of my first thoughts was, like, \u201cWow, they stole my voice.\u201d I mean, not me specifically; I\u2019m not that vain, despite what the AI podcast may have led you to believe [laughs]."]},{"begin":"1133.240","end":"1134.640","lines":["[Laughs] Your ego has been inflated."]},{"begin":"1134.640","end":"1182.520","lines":["[Laughs] Yeah, yeah. But so much of the texture that makes this audio sound engaging and real feels just ripped straight from existing podcasts. And I know it\u2019s ripped from existing podcasts because a lot of the stuff that I\u2019m hearing\u2014which is, like, breath sounds and filler words and, like, a little bit of uptalk, some, some giggling, occasional vocal fry\u2014this is the stuff I get angry emails about from gentlemen of a certain age [laughs] who think I\u2019m ruining the great tradition of radio broadcasting. And they\u2019re making this sound real by, like, breaking the same so-called rules that me and other women and queer people on podcasts have been criticized for breaking. So I won\u2019t lie, that feels kind of gross to me."]},{"begin":"1182.520","end":"1195.880","lines":["Yeah, one of the things that Steven mentioned, too, was they wanted the sound of, like, this great radio broadcasting show. And it is worth noting that Science Quickly is on YouTube\u2014and all of our hard work at Scientific American and the hard work of other outlets."]},{"begin":"1195.880","end":"1202.400","lines":["So, the question remains: How will this be used? Will it be used responsibly? Here is what Anjana thinks."]},{"begin":"1202.400","end":"1211.960","lines":["Right now it seems more like everyone\u2019s just dazzled by what it can do rather than: What are we gonna use it for? Do we really need these, you know, capabilities?"]},{"begin":"1211.960","end":"1228.160","lines":["I can think of one or two examples, I think, in the health care context: Can you generate clear summaries for health literacy or your doctor\u2019s notes? So this may be a good way to give, like, a summary of\u2014rather than giving a piece of paper to read."]},{"begin":"1228.160","end":"1245.560","lines":["Is that going to have some challenges? What are some specific issues we need to be looking for? We\u2019ve just unleashed this tool on people, and we\u2019re still catching up. We will need audit studies and then look at trustworthiness, assurance, and so forth."]},{"begin":"1245.560","end":"1252.800","lines":["So what\u2019s the right way to responsibly use NotebookLM? We are still figuring it out [laughs]."]},{"begin":"1252.800","end":"1267.080","lines":["Well, I think where I want to leave us is with an important point from Emily, which is: you shouldn\u2019t let the incredible fluency of these AI-generated voices fool you into thinking and talking about these models as if they\u2019re human."]},{"begin":"1267.080","end":"1284.800","lines":["Emily coined a term that\u2019s been used quite widely called the \u201cstochastic parrot.\u201d Like, when a parrot says, like, \u201cPolly want a cracker,\u201d it\u2019s not really connected to meaning; it\u2019s just mimicking. She also sometimes calls these large language models, quote, \u201csynthetic text extruding machines,\u201d she said because it\u2019s more accurate to what they\u2019re actually doing and also sounds a little gross."]},{"begin":"1284.800","end":"1292.560","lines":["But I think she\u2019s getting at an important point there, right? It\u2019s, like, this\u2014just a philosophical question of: What is language for, and what are we communicating when we say words?"]},{"begin":"1292.560","end":"1315.800","lines":["Languages are systems that are pairings of form and meaning, systems of signs. So when we speak we are using word forms because they relate to specific meanings, but language models only have access to the form. And so they can give us stuff that looks good, it\u2019s got the right shape, but there\u2019s no relationship to meaning, no communicative intent, no accountability."]},{"begin":"1315.800","end":"1360.880","lines":["I guess sort of the takeaway on my complicated feelings on this is: I\u2019m not worried that my job is gonna be stolen by a collection of tabs [laughs] being processed by Google because it is a lot of work to be accurate. And if people find this kind of engaging conversation a more accessible way to sort through really dense text, that\u2019s awesome. But, of course, there are so many caveats about where the training data has come from, bias, accuracy. So I think it\u2019s, like\u2014just people need to be really aware of what they\u2019re getting, and I don\u2019t know that I feel that the products themselves are doing a great job of making people aware of those caveats."]},{"begin":"1360.880","end":"1379.240","lines":["Yeah, there\u2019s usually just kind of a disclaimer at the bottom. I think one of the things that this whole AI boom\u2014like this, the AI search features\u2014have made me feel kind of uncomfortable about: Are we going to be expected, and have we already started to expect, our information to contain just that more amount of mistruths? It\u2019s something that I just worry about."]},{"begin":"1379.240","end":"1386.960","lines":["Well, Allison, thanks so much for coming on to chat about this and also for having a couple of AI voices gas me up. Thank you."]},{"begin":"1386.960","end":"1387.640","lines":["Thank you."]},{"begin":"1387.640","end":"1396.000","lines":["That\u2019s all for today\u2019s episode. We\u2019ll be back on Friday with Episode One of a four-part miniseries on the future of animal conservation."]},{"begin":"1396.000","end":"1416.320","lines":["Science Quickly is produced by me, Rachel Feltman, along with Fonda Mwangi, Kelso Harper, Madison Goldberg and Jeff DelViscio. Today\u2019s episode was reported and co-hosted by Allison Parshall. Shayna Posses and Aaron Shattuck fact-check our show. Our theme music was composed by Dominic Smith. Subscribe to Scientific American for more up-to-date and in-depth science news."]},{"begin":"1416.320","end":"1425.360","lines":["For Scientific American, this is Rachel Feltman. See you next time!"]}],"duration":1425}