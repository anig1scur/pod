{"title":"Inside the Race to Protect Artists from Artificial Intelligence","img":"https://static.scientificamerican.com/dam/m/76169718d87a40f1/original/ai_art-ezgif-com-optimize.gif","url":"https://www.scientificamerican.com/podcast/episode/inside-the-race-to-protect-artists-from-artificial-intelligence/","audio":"https://traffic.megaphone.fm/SAM5790583210.mp3?updated=1711729278","intro":["AI-generated art is creating new ethical issues\u2014and competition\u2014for digital artists. Nightshade and Glaze are two tools helping creators fight back."],"authors":["Rachel Feltman","Lauren Leffer"],"category":["Artificial Intelligence"],"transcript":[{"author":"Lauren Leffer: ","text":"Generative artificial intelligence tools can now instantly produce images from text prompts. It\u2019s neat tech, but could mean trouble for professional artists."},{"author":"Rachel Feltman: ","text":"Yeah, because thoseAI tools make it really easy to instantly just rip off someone\u2019s style."},{"author":"Leffer","text":"That\u2019s right, generative AI, which is trained on real peoples\u2019 work, can end up really hurting the artists that enable its existence. But some have started fighting back with nifty technical tools of their own."},{"author":"Feltman","text":"It turns out that the pixel is mightier than the sword. I\u2019m Rachel Feltman, a new member of the Science, Quickly team. Leffer: And I\u2019m Lauren Leffer, contributing writer at Scientific American."},{"author":"Feltman","text":"And you\u2019re listening to Scientific American\u2019s Science, Quickly podcast. [Clip: Show theme music]"},{"author":"Feltman","text":"So I have zero talent as a visual artist myself, but it seems like folks in that field have really been feeling the pressure from generative AI."},{"author":"Leffer","text":"Absolutely, yeah. I\u2019ve heard from friends who\u2019ve had a harder time securing paid commissions than ever before. You know, people figure they can just whip up an AI-generated image instead of paying an actual human to do the work. Some even use AI to overtly dupe specific artists. But there\u2019s at least one little tiny spot of hope. It\u2019s this small way for artists to take back a scrap of control over their work and digital presence."},{"author":"Feltman","text":"It\u2019s like a form of self-defense."},{"author":"Leffer","text":"Right, let\u2019s call it self-defense, but it\u2019s also a little bit of offense. It\u2019s this pair of free-to-use computer programs called Glaze and Nightshade developed by a team of University of Chicago computer scientists, in collaboration with artists. Both tools add algorithmic cloaks over the tops of digital images that change how AI models interpret the picture, but keep it looking basically unchanged to a human eye."},{"author":"Feltman","text":"So once you slap one of these filters on your artwork, does that make it effectively off-limits to an AI training model?"},{"author":"Leffer","text":"Yeah, basically. It can\u2019t be used to train generative image models in the same way once it\u2019s been \u201cglazed\u201d or \u201cshaded\u201d \u2013 which is what they call an image passed through Nightshade. And, with Nightshade specifically, it actually might mess up a model\u2019s other training\u2013 it throws a wrench in the whole process."},{"author":"Feltman","text":"That sounds like karma to me. I\u2019d love to hear more about how that works. But before we dig into the technical stuff, I have to ask: shouldn\u2019t artists already be protected by copyright laws? Like, why do we need these technical tools to begin with?"},{"author":"Leffer","text":"Yeah, great question\u2013 so right now, whether or not copyright law defends against creative work being used to train AI, it\u2019s this really big, unresolved legal gray area, kind of a floating question mark. There are multiple pending lawsuits on the subject, including ones brought by artists against AI image generators, and even The New York Times against OpenAI, because the tech company used the newspaper\u2019s articles to train its large language models. So far, AI companies have claimed that pulling digital content into training databases falls under this protection clause of fair use."},{"author":"Feltman","text":"And I guess as long as those cases are still playing out, in the meantime, artists just can\u2019t really avoid feeding that AI monster if they want to promote their work online. Which, obviously, they have to do."},{"author":"Leffer","text":"Right, exactly. Glaze and Nightshade\u2013 and similar tools, there are other ones out there like Mist\u2013 they aren\u2019t permanent solutions. But they\u2019re offering artists a little bit of peace of mind in the interim."},{"author":"Feltman","text":"Great names all around.How did these tools come to be?"},{"author":"Leffer","text":"Let\u2019s start with a little bit of background. Before we had generative AI, there was facial recognition AI. That laid the technical groundwork for adversarial filters, which adjust photos to prevent them from being recognized by software. The developers of Glaze and Nightshade, they\u2019d previously released one of these tools, called Fawkes, after the V for Vendetta Guy Fawkes mask."},{"author":"Feltman","text":"Another great name."},{"author":"Leffer","text":"Yeah it\u2019s very into, like, the tech-dystopia world."},{"author":"Feltman","text":"Totally."},{"author":"Leffer","text":"Fawkes cloaked faces, and in 2023, the research team started hearing from artists asking if Fawkes would work help to hide their work from AI too. Initially, you know, the answer was no, but it did prompt the computer scientists to begin developing programs that could help artists cloak work."},{"author":"Feltman","text":"So what do these tools do?"},{"author":"Leffer","text":"Glaze and Nightshade, they do slightly different things, but let's start with the similarities. Both programs apply filters. They alter the pixels in digital pictures in subtle ways that are confusing to machine learning models but unobtrusive (mostly) to humans."},{"author":"Feltman","text":"Very cool in theory, but how does it work?"},{"author":"Leffer","text":"You know how, with optical illusions, a tiny tweak can suddenly make you see a totally different thing? Feltman: Ah yes, like the infamous dress that was definitely blue and black, and not white and gold at all."},{"author":"Leffer","text":"Right there with you. Yeah, so optical illusions happen because human perception is imperfect, we have these quirks inherent to how our brains interpret what we see. For instance, you know, people have a tendency to see human faces in inanimate objects."},{"author":"Feltman","text":"So true, like every US power outlet is just a scared lil guy."},{"author":"Leffer","text":"Absolutely, yeah\u2013 power outlets, cars, mailboxes\u2013 all of them have their own faces and personalities."},{"author":"Feltman","text":"100%."},{"author":"Leffer","text":"Computers don\u2019t see the world the same way that humans do, but they have their own perceptual vulnerabilities. And the developers of Glaze and Nightshade built an algorithm that figures out those quirks and the best way to exploit them, and then modifies an image accordingly. It\u2019s a delicate balancing act. You want to stump the AI model, but you also want to keep things stable enough that a human viewer doesn\u2019t notice much of a change. In fact, the developers kind of got to that balanced point through trial and error."},{"author":"Feltman","text":"Yeah, that makes sense. It\u2019s really hard to mask and distort an image without masking and distorting an image. So they\u2019re able to do this in a way that we can\u2019t perceive, but what does that look like from the AI\u2019s perspective?"},{"author":"Leffer","text":"Another great question.To train an image-generating AI model to pump out pictures, you give it lots of images along with descriptive text. The model learns to associate certain words with visual features\u2013 think shapes or colors, but really it\u2019s something else we can\u2019t necessarily perceive because it\u2019s a computer. And under the hood, all of these associations are stored within basically multidimensional maps. Similar concepts and types of features are clustered near one another."},{"author":"Leffer","text":"With the algorithm that underlie Glaze and Nightshade, the computer scientists strategically force associations between unrelated concepts, so they move points on that multidimensional map closer and closer together."},{"author":"Feltman","text":"Yeah, I think I can wrap my head around how that would confuse an AI model."},{"author":"Leffer","text":"Yeah, it\u2019s all still a little hand wavey because what it really comes down to is some complex math. Ben Zhao, the lead researcher at University of Chicago behind these cloaking programs, said that developing the algorithms was akin to solving two sets of linear equations."},{"author":"Feltman","text":"Not my strong suit. So I will take his word for it."},{"author":"Leffer","text":"Me either. That\u2019s why we\u2019re at a podcast instead."},{"author":"Feltman","text":"So why two tools? How are these different?"},{"author":"Leffer","text":"Glaze came out first. It was kind of the entry, the foray, into this world. It\u2019s very focused on cloaking an artists\u2019 style. So this thing kept happening to prominent digital artists where someone would take an open source generative AI model and train it on just that artist\u2019s work. That gave them a tool for producing style mimics. Obviously this can mean fewer paid opportunities for the artist in question, but it also opens creators up to reputational threats."},{"author":"Leffer","text":"You could use one of these style mimics to make it seem like an artist had created a really offensive image, or something else that they would never make."},{"author":"Feltman","text":"That sounds like such a nightmare."},{"author":"Leffer","text":"Absolutely, in the same nightmare zone as deep fakes and everything happening with generative AI right now. So because of that, Zhao and his colleagues put out Glaze, which tricks AI models into perceiving the wrong style. Let\u2019s say your aesthetic is very cutesy, and bubbly and cartoon-ey. If you Glaze your work, an AI model might instead see Picasso-esque cubism. It makes it way harder to train style mimics."},{"author":"Feltman","text":"Very cool. You mentioned that these tools can also play a little bit of offense against AI art generators. Is that where Nightshade comes in?"},{"author":"Leffer","text":"That\u2019s right. An image cloaked in Nightshade will teach AI to incorrectly associate not just styles but also fundamental ideas and images. As a hypothetical example, it would only take a few hundred Nightshade-treated images to retrain a model to think cats are dogs. Zhao says that hundreds of thousands of people have already downloaded and begun deploying Nightshade."},{"author":"Leffer","text":"And so his hope\u2013 and his co-researcher\u2019s hope and the artist\u2019s hope\u2013 is that with all of these images out there, it will become costly enough and annoying enough for AI companies to weed through masked picture, they\u2019ll be more incentivized to pay artists willing to license their work for training instead of just trawling the entire web."},{"author":"Feltman","text":"And if nothing else, it\u2019s just very satisfying."},{"author":"Leffer","text":"Yeah, it\u2019s catharsis at some baseline level."},{"author":"Feltman","text":"Yeah, so it sounds like the idea is to kind of even out the power differential between AI developers and artists, is that right?"},{"author":"Leffer","text":"Yeah, these tools, they definitely tip the balance a little bit, but they\u2019re certainly not a complete solution\u2013they\u2019re more like a stop gap. For one, artists can\u2019t retroactively protect any art that\u2019s already been hoovered up into AI training datasets, they can only apply these tools to newer work. Plus, AI technology is advancing super super fast. I spoke with some AI experts who were quick to point out that neither Glaze nor Nightshade are future proof. They could be compromised moving forward. AI models could just change into things that have different structure and architecture."},{"author":"Leffer","text":"Already, one group of machine learning academics has partially succeeded at getting around the Glaze cloak."},{"author":"Feltman","text":"Wow that was fast. That\u2019s a few months after it came out, right?"},{"author":"Leffer","text":"Yeah, it\u2019s quick, though that\u2019s kind of the nature of digital security, as Zhao told me in his own words: \u201cit\u2019s always a cat-and-mouse game.\u201d"},{"author":"Feltman","text":"And I guess even if Glaze and Nightshade continue to work perfectly, it\u2019s still unfair for artists to have to take those extra steps. Leffer: Yes, absolutely great point. I spoke with a professional illustrator, Mignon Zakuga, who\u2019s been really enthusiastic about Glaze and Nightshade. She was involved in beta testing, and still uses both cloaks regularly when she uploads her work. But even she said that passing images through the filters is not the greatest or easiest process."},{"author":"Feltman","text":"It can take a couple of hours, and even though they\u2019re not supposed to be noticeable, often the visual changes are, at least to her. And especially to her, as the artist who made the image. So Zakuga told me it\u2019s a compromise she\u2019s willing to deal with for now. But clearly, artists deserve better, more robust protections."},{"author":"Feltman","text":"Yeah like\u2013 and I know this is wild\u2013 but what about actual policy or legislation?"},{"author":"Leffer","text":"100%, it would be great to get to a point where all of that is clarified especially in policy and law. But no one really knows what that should or will look like. Will copyright end up being enforced against AI? Do we need some whole new suite of protective laws? But at the very least, programs like Glaze and Nightshade, they offer us a little more time to figure that all out. [Clip: Show theme music]"},{"author":"Leffer","text":"Science Quickly is produced by Jeff DelViscio, Tulika Bose, Rachel Feltman, Kelso Harper and Carin Leong. Our show is edited by Elah Feder and Alexa Lim. Our theme music was composed by Dominic Smith."},{"author":"Feltman","text":"Don\u2019t forget to subscribe to Science Quickly wherever you get your podcasts. For more in-depth science news and features, go to ScientificAmerican.com. And if you like the show, give us a rating or review!"},{"author":"Leffer","text":"For Scientific American\u2019s Science Quickly, I\u2019m Lauren Leffer."},{"author":"Feltman","text":"I\u2019m Rachel Feltman. See you next time!"}],"wave_peaks":[2392,2027,3212,2265,15471,16079,15894,15442,14663,11842,14464,14984,14849,15412,15203,15131,15393,15237,15029,15429,14876,15016,15294,14599,15886,15907,16361,15136,16142,15800,11268,1909,14815,15350,15166,15621,15490,1570,1501,15258,15712,15270,15512,15546,8900,15772,15662,14826,1938,15156,15988,14815,14541,15353,14721,14937,15273,4492,2405,2165,15222,15590,15489,15309,15695,14945,15594,15150,11208,15403,16182,16252,13717,15280,15279,15529,14617,15210,15660,15262,13977,15340,15283,15876,14849,14969,12355,1597,1787,15748,15274,16789,16195,15882,14572,15066,15126,15569,14938,15097,16039,16269,17062,15017,10922,11052,2045,1933,14801,17153,15287,15968,16135,15352,16432,15546,15198,15384,14839,15373,12916,15220,15680,15428,15668,16131,16212,15938,2827,14330,14570,15008,15145,11043,15132,16006,15822,15714,13349,1103,15140,14267,14700,14842,15943,16118,15740,13884,15576,15477,15415,15302,15082,15315,15057,15437,2917,15395,16899,16073,15147,15562,15256,14864,14870,15141,15046,15019,15342,15330,14857,14929,6612,1811,14002,15192,16314,16678,18542,17786,11507,4543,8565,5553,8335,5085,6714,7222,5204,7984,3819,9794,2531,1520,980,444,80,383,481,663,1102,15308,12179,17320,9605,10277,6504,5022,8481,12692,9298,11318,7218,8424,4979,9961,3409,2433,14162,12657,10398,10361,6855,10573,18540,9956,10491,4966,11623,5145,1414,14747,13962,16953,13512,10600,10988,6897,7834,6583,9901,7494,6441,12384,10906,15018,16811,2546,10891,12840,11758,10563,14048,11993,8208,10235,7131,10287,6593,8015,8174,9186,11638,8855,8851,8395,8149,4296,856,12349,11662,14353,15416,15583,20673,4396,7070,12760,7368,6059,8070,4153,5905,16286,17376,11698,11812,14753,14417,9219,7831,10245,2195,19121,10246,19607,12762,10124,13335,14869,8699,6783,6103,14395,18219,14254,9989,11785,16025,14807,6552,8332,5901,638,14482,17604,6239,17779,10601,16070,4982,19889,10216,16491,17293,3807,4409,5421,5864,6050,6949,7106,7009,5946,4809,5581,3792,3689,1026,754,574,591,562,442,363,13074,14315,10937,3321,7700,11867,11780,5434,10816,10383,14580,13735,10438,11243,12502,9702,14534,8104,13466,9759,13419,13613,17626,12650,14609,8964,9114,13632,17504,20961,5665,10849,17735,18875,14113,11131,6527,13552,11018,5634,7383,7319,10305,6194,6393,9205,8424,7518,10643,11473,6087,16254,11619,9870,9418,9808,10341,8425,7891,11287,5184,5960,5153,6014,7,16841,12423,7343,6314,13405,7524,10685,5314,4861,6886,15346,5856,6109,8452,9058,6282,8456,7724,4713,7541,15120,9233,10141,9148,12821,9746,10883,12706,10084,13043,15631,15477,7400,7704,8622,9735,6369,7225,9136,5408,9927,11588,18261,20462,12401,2182,11728,10656,11579,7235,8328,13603,12677,15627,9149,11389,12748,8948,1037,20,15030,13830,14713,9726,9551,11821,11594,17236,17058,8756,13424,8854,12900,12166,9750,8266,10982,6072,14348,7487,6914,4015,1681,14938,11714,14398,9845,3597,103,19667,6569,15457,14023,11792,7507,10454,7801,11707,9913,7772,9107,14336,11739,9756,13285,11690,9216,7687,7522,8821,8054,7343,10384,10569,9348,9106,12942,7128,6656,10409,13,10624,8430,11971,18597,19287,10285,12191,15726,9498,17194,21453,18123,17092,8718,14190,14433,6122,12361,14128,15902,10333,11184,136,11023,22489,15060,6387,11485,4255,16801,9355,10752,8601,12186,9015,8772,8899,7343,6217,10032,9904,7640,6102,11598,10429,6166,8073,3740,4101,6381,1641,7580,9849,5183,5391,533,12255,11253,14630,9393,6886,10019,9007,22189,13332,11032,10209,15570,17714,5108,9808,13472,22125,14863,8063,8600,7699,1092,9179,1550,25252,15887,14974,14944,11731,10964,9664,5530,14943,14878,12645,22523,17551,8865,16178,11836,11878,11522,7835,12738,17354,625,9,15125,18655,13055,16813,17632,22156,16885,17864,11931,16067,20007,20221,14975,14957,12368,18109,9231,8394,7018,15127,8132,6879,9884,11672,1083,21861,13309,10747,12520,18841,7863,12844,13848,9339,8075,11514,12300,11178,10086,12030,14663,8577,11298,6413,5996,5863,13866,9816,2,16039,11400,11041,12843,8752,14048,15552,15669,13089,6463,13213,9037,9554,8591,9285,16751,24967,10891,5626,11673,13334,12145,14453,5485,6694,15142,16569,14513,12859,10287,15510,12851,13215,17376,14938,13173,10524,9208,5396,15401,7309,4275,16141,12501,8918,6426,9324,14708,10561,8437,8774,11931,9037,6591,454,1673,17704,13545,16404,10266,9889,9387,9375,13118,11891,11717,11690,8277,11335,9035,9381,12867,12420,10731,6130,10872,15238,11489,9611,10209,6078,2765,17351,19471,19504,17444,14482,17042,12069,16454,11684,9749,13433,18309,7148,18376,11850,13417,8771,15615,16052,9215,19510,16324,14064,14272,11732,11252,8101,9452,19815,18944,8240,26565,11344,8051,10093,3789,12885,21308,25564,6546,9562,12214,12758,12610,11848,16480,12643,14245,10599,10050,8472,2553,15216,13837,14443,6166,11189,13349,11209,11312,9178,8531,12997,6664,9833,5453,8166,3794,19992,8679,14415,12195,4969,19072,11524,15231,15336,10267,31,17974,13466,12197,16758,11750,6171,11980,15593,16704,11245,13158,11854,10936,7070,13424,12624,5932,4890,10455,1622,27173,13942,10786,7340,12346,11508,12580,11811,17439,8134,7193,7361,10520,5664,8768,13454,8168,11886,5628,10762,15261,9960,8367,8731,8481,4,17272,13854,14358,8596,7409,10408,13864,8745,7935,7737,9120,5858,7599,9037,12420,14919,15410,6847,7092,5664,8955,7900,8434,231,23033,21236,25985,20277,18110,20508,15622,7766,16721,7095,8199,13361,5848,8185,5990,13842,13557,7,15648,3308,16389,2734,13218,13241,6281,15368,14447,12553,12625,8133,7568,9110,9701,12227,11799,15556,13187,17639,10920,11898,10360,10604,12738,17140,13244,11262,20180,14380,8786,15018,8849,477,17518,12259,12670,10780,10649,8307,11913,15074,15260,8325,13791,10989,10399,12251,7283,12687,10247,19906,17233,11246,8162,5357,1264,20274,15870,10419,20090,9465,194,9,16790,15179,15785,6704,11031,8688,7828,10326,13292,14322,10314,10435,3046,12585,15042,16407,13222,11150,8019,12030,15490,10096,8260,8302,7643,8195,12871,12086,12049,12078,9841,8522,8319,11250,10153,10893,11246,13287,9002,8080,6338,13623,6124,6008,5717,7808,14713,20578,12869,3072,4714,17157,16951,15091,18731,18513,13829,13392,511,16921,14924,15455,14000,15060,10839,17136,9809,11543,9187,9019,16720,16045,6906,11374,6681,7397,6058,22384,20711,16249,11643,17772,16439,10377,15560,22101,14240,15718,11784,11883,11978,13938,17032,8226,15717,20751,14623,11249,18431,28039,24853,13856,16449,8,17634,11943,17211,9597,11979,13989,13608,6960,13660,12625,12344,5075,5950,10699,12042,11733,11547,16436,6852,10431,17409,12212,9393,9983,7746,6134,20,17744,16532,10200,19789,13641,12432,9496,7341,12428,10566,9837,10573,9331,8894,2388,11057,7970,8857,17183,11911,16828,25301,16370,7796,6063,10227,8830,8246,20083,12974,28157,8942,5765,14440,4831,16286,14466,2415,14598,8197,14315,17377,6308,13134,12853,10123,8205,7513,7090,4371,11464,7180,2869,17235,12348,9712,10768,12318,9134,10934,13061,13422,6144,12882,8299,11403,8656,14219,10008,7327,10573,4837,45,12453,7204,13715,9823,8560,9739,7576,6651,13625,11232,11822,13909,13430,17811,15309,14234,12266,9635,14369,10141,8759,9906,16883,10276,9773,9271,7867,2980,10316,10840,16801,12051,12618,9607,6388,5747,14001,13418,12887,13694,9043,9056,11060,12193,8034,12355,10473,10323,8389,8844,10820,8487,10306,5723,6453,5020,3796,15143,20810,13598,14614,13960,13970,9771,16533,521,17211,7838,3026,14317,10970,7085,12271,7653,4853,19019,21379,12407,10706,14559,808,12775,24240,17473,10250,7,8017,17067,14033,12013,14044,13143,17109,107,10885,22362,18281,18661,11455,16511,6556,14375,11724,14036,20376,16185,11631,9874,15272,7057,7578,17522,18429,10964,18128,8914,13760,12842,10154,3284,13907,9684,4357,10252,4927,5777,41,19310,14776,8261,10671,9697,8186,8231,6795,12263,4846,9497,3305,11507,6181,7770,9155,7856,7989,6301,13582,2400,10877,9501,7178,5290,14390,12875,10094,13435,6229,6119,10392,12109,8861,10962,13113,8177,11273,12189,9843,10395,7072,7728,11098,8501,5426,6427,3066,10410,7023,15389,13520,16300,11374,9335,8053,8316,10099,11797,7437,5332,16297,9611,9535,8558,6274,15142,3100,499,13112,12756,11825,10734,10279,10683,6701,8311,9711,10039,11341,6805,9533,112,1905,14776,17280,11928,9238,7136,15226,13485,14633,13922,10974,10839,10529,6914,10876,9358,7428,8471,6043,8808,8029,6456,12367,8670,8583,13167,13245,9645,7446,11506,9960,8829,7475,3909,4921,21322,18908,26095,20131,16473,21617,16944,5519,5313,8164,10474,9861,14669,17861,13780,9107,7145,9371,7816,7418,8670,10620,12233,5550,8049,7041,10666,11395,13290,10672,7924,9797,6541,5816,12862,10022,8071,4940,6835,6905,335,13541,10276,8510,9704,7461,6018,9772,5665,6339,7302,6985,4093,1370,11012,7786,9079,10739,26553,12673,12078,18024,10012,16356,14894,14642,7890,10454,15934,14782,15222,18950,5404,21804,13816,8237,22422,10621,10800,4,16406,13898,12270,9200,9529,7944,5204,7575,7212,5978,6196,4950,8973,7604,7215,6293,8965,11895,12701,12339,7615,8564,11607,9207,9840,2752,18693,9239,13024,9899,15147,8470,6603,12398,9685,14120,10861,10189,10480,9626,8415,10100,9426,10056,25229,14983,10064,10735,11174,15802,14752,10047,8826,3080,3136,22569,18727,14876,9656,14050,7563,19075,10443,8643,12338,16197,8686,10306,12149,9898,8100,10532,10450,17037,11360,11064,14581,20867,12251,12153,10613,13218,7459,8462,14830,7917,6822,5898,8168,7488,18906,7692,8845,6425,11394,1784,19792,12915,8907,13262,8103,13308,6096,11151,11227,12651,12283,12438,4500,2201,16164,17676,3156,17247,9896,2956,6879,14672,10828,11380,8659,7620,9574,7469,5223,4132,10076,5586,10237,10337,10769,4030,7566,11436,11656,9423,5563,11637,13777,15966,13264,12495,14834,11491,9496,7956,16901,23185,23046,9885,4074,12053,11790,12562,13261,13240,12210,13216,15269,7929,12116,7695,13093,12142,10088,13049,11179,42,23095,7786,10780,10326,18031,15180,9677,9593,9493,9133,5148,9909,9697,8120,9944,10733,13662,17151,16837,15467,8000,6186,10402,3628,1025,7682,13757,7158,12230,18097,11714,12595,14877,17058,9754,17169,10991,15661,10547,15584,13699,14714,13778,9248,8052,6338,13642,14346,10455,11868,8065,9428,9549,19105,15541,4018,17110,16144,12172,10709,9954,9427,9433,15982,8300,15529,7672,7732,18639,12444,1647,15120,7372,14504,17583,10249,16081,9377,12015,4821,6069,280,21197,13021,9777,10701,9117,9528,9403,6588,11056,9612,10167,7754,15696,13090,6502,10919,9120,12553,10094,16088,10564,8466,1364,8360,21628,23228,12770,12044,15613,11798,12429,6495,14613,16229,11516,12903,12188,9784,10548,10917,8344,16581,13045,11201,9433,9438,5600,10373,7372,9780,11241,10451,10159,12252,24062,16589,13144,6613,8399,18435,15141,14629,9831,15740,6244,12102,12606,9502,8868,15686,14929,5851,7558,7470,12776,7091,10300,9666,5858,10501,10729,14978,9716,14417,8616,7007,8486,7254,10555,9249,12182,12228,12867,9696,8988,3878,15815,16805,16126,6667,12648,13142,22216,20412,24714,17820,27966,27302,28258,24509,12751,18011,15136,18026,10265,7779,26161,27171,20656,15354,19211,16745,19850,16862,19277,8082,12649,16395,10828,25835,16071,14574,6274,16526,17563,10022,6931,13917,6395,21168,12533,8386,22643,7020,8013,7355,11452,14043,12724,14205,17188,8485,9138,10395,12998,13596,15501,8303,13364,9035,5038,5313,11066,17630,16853,14935,228,14038,19180,19528,18298,13798,14444,17986,7894,23967,10976,21439,16114,10883,13064,13014,9790,10210,8627,14303,14597,10980,8001,10193,5433,3056,7544,9614,19102,16854,17240,10508,10377,11692,8411,8650,8458,18787,18638,10395,12119,10408,15357,17794,10212,12511,18841,18270,16019,17292,15226,13395,11998,18699,11190,9166,6922,9048,8247,17676,16760,8847,10201,13292,10148,9281,4798,4127,4640,7354,4897,8995,9909,8054,7214,14475,8067,11422,12552,7107,19283,18537,16233,11903,9486,9375,14111,13082,5948,16942,14414,7130,12616,14348,11648,8330,10547,4639,18343,20308,13508,20263,13002,13115,20153,12184,20418,11014,17247,16843,16071,4129,13603,12892,10133,8863,11041,5855,8799,7255,8358,15359,15096,11834,7511,9278,10389,11260,11252,9944,7225,13455,11923,7550,8706,7830,19264,9629,11882,18026,9501,10951,14772,11429,7759,14951,12582,14811,15705,22,23228,20024,28189,28152,27650,22347,18780,12541,16451,6591,28194,2233,20953,4204,21886,13029,10349,9032,14794,19754,13717,10313,11532,14347,8525,16590,22285,11158,17843,18727,10322,11617,9268,6301,6338,8429,8454,10165,10490,9402,8498,8472,12626,10507,9764,12720,8547,9418,9583,14041,1973,12683,13776,9487,12077,15801,9488,9162,8349,14442,15446,9410,12909,12860,11022,13517,6099,7643,17597,7733,12093,14631,11657,11358,5830,18720,13183,14650,14279,8593,10221,8675,9502,19840,12031,8825,9868,4870,14880,16704,9280,14796,15597,6396,12060,9090,9469,12622,4678,14795,5911,4933,32,12772,10477,11276,11404,15629,12629,8085,11109,7443,13169,8205,6346,8597,14417,6634,10796,12125,9843,11049,10464,10727,2217,21416,25085,12478,11031,13482,5010,18046,8729,19333,20514,28181,18246,22380,24843,23275,11897,15686,10014,12077,12678,18679,14702,9969,14259,9922,16289,11416,16083,9207,15655,9090,11953,4889,16071,8210,5153,7516,7980,6785,10326,875,12680,11666,9696,10257,9191,9275,9618,9717,7523,9676,6151,7231,5661,10936,14066,16715,14958,10912,13811,11110,12842,12944,10238,9716,3468,20798,18830,9403,9911,13452,12980,12554,8758,11866,10469,6391,1109,11320,8385,7519,5882,7235,8423,10576,9387,7789,8399,13765,12872,15267,12937,13792,7152,1078,1034,1314,1548,3247,2310,3355,24571,19058,13621,9376,13100,8756,12170,9590,11906,10345,8102,12901,7540,12457,16037,14787,11356,7991,3828,12852,12521,16277,16310,11439,16126,10067,8896,3959,19484,12204,12283,15963,18934,10418,9257,15967,25114,21563,20270,24866,19102,17545,23891,25185,13831,19542,20607,3220,15811,11036,19076,16213,9504,11059,11222,16582,20177,10193,13955,18201,10397,8602,18903,14262,22441,15054,16342,10327,10926,3572,17237,9787,12433,12272,9232,12016,17774,13540,12626,5472,20966,16697,5862,5558,14551,18387,10794,11231,9892,9718,8852,10456,8828,6469,8755,8574,11276,10544,10360,10195,9283,9463,8928,10197,9042,11011,10816,10489,9418,7490,7243,6038,3876,1656,925,11643,9401,7092,4707,2301,831,297,155,51,23,4,0,0,0,0,0],"fragments":[{"begin":"0.000","end":"22.840","lines":["Generative artificial intelligence tools can now instantly produce images from text prompts. It\u2019s neat tech, but could mean trouble for professional artists."]},{"begin":"22.840","end":"34.040","lines":["Yeah, because thoseAI tools make it really easy to instantly just rip off someone\u2019s style."]},{"begin":"34.040","end":"65.640","lines":["That\u2019s right, generative AI, which is trained on real peoples\u2019 work, can end up really hurting the artists that enable its existence. But some have started fighting back with nifty technical tools of their own."]},{"begin":"65.640","end":"88.160","lines":["It turns out that the pixel is mightier than the sword. I\u2019m Rachel Feltman, a new member of the Science, Quickly team. Leffer: And I\u2019m Lauren Leffer, contributing writer at Scientific American."]},{"begin":"88.160","end":"103.600","lines":["And you\u2019re listening to Scientific American\u2019s Science, Quickly podcast. [Clip: Show theme music]"]},{"begin":"103.600","end":"112.160","lines":["So I have zero talent as a visual artist myself, but it seems like folks in that field have really been feeling the pressure from generative AI."]},{"begin":"112.160","end":"135.000","lines":["Absolutely, yeah. I\u2019ve heard from friends who\u2019ve had a harder time securing paid commissions than ever before. You know, people figure they can just whip up an AI-generated image instead of paying an actual human to do the work. Some even use AI to overtly dupe specific artists. But there\u2019s at least one little tiny spot of hope. It\u2019s this small way for artists to take back a scrap of control over their work and digital presence."]},{"begin":"135.000","end":"136.800","lines":["It\u2019s like a form of self-defense."]},{"begin":"136.800","end":"159.360","lines":["Right, let\u2019s call it self-defense, but it\u2019s also a little bit of offense. It\u2019s this pair of free-to-use computer programs called Glaze and Nightshade developed by a team of University of Chicago computer scientists, in collaboration with artists. Both tools add algorithmic cloaks over the tops of digital images that change how AI models interpret the picture, but keep it looking basically unchanged to a human eye."]},{"begin":"159.360","end":"166.400","lines":["So once you slap one of these filters on your artwork, does that make it effectively off-limits to an AI training model?"]},{"begin":"166.400","end":"183.280","lines":["Yeah, basically. It can\u2019t be used to train generative image models in the same way once it\u2019s been \u201cglazed\u201d or \u201cshaded\u201d \u2013 which is what they call an image passed through Nightshade. And, with Nightshade specifically, it actually might mess up a model\u2019s other training\u2013 it throws a wrench in the whole process."]},{"begin":"183.280","end":"197.720","lines":["That sounds like karma to me. I\u2019d love to hear more about how that works. But before we dig into the technical stuff, I have to ask: shouldn\u2019t artists already be protected by copyright laws? Like, why do we need these technical tools to begin with?"]},{"begin":"197.720","end":"229.560","lines":["Yeah, great question\u2013 so right now, whether or not copyright law defends against creative work being used to train AI, it\u2019s this really big, unresolved legal gray area, kind of a floating question mark. There are multiple pending lawsuits on the subject, including ones brought by artists against AI image generators, and even The New York Times against OpenAI, because the tech company used the newspaper\u2019s articles to train its large language models. So far, AI companies have claimed that pulling digital content into training databases falls under this protection clause of fair use."]},{"begin":"229.560","end":"240.560","lines":["And I guess as long as those cases are still playing out, in the meantime, artists just can\u2019t really avoid feeding that AI monster if they want to promote their work online. Which, obviously, they have to do."]},{"begin":"240.560","end":"249.880","lines":["Right, exactly. Glaze and Nightshade\u2013 and similar tools, there are other ones out there like Mist\u2013 they aren\u2019t permanent solutions. But they\u2019re offering artists a little bit of peace of mind in the interim."]},{"begin":"249.880","end":"253.320","lines":["Great names all around.How did these tools come to be?"]},{"begin":"253.320","end":"274.240","lines":["Let\u2019s start with a little bit of background. Before we had generative AI, there was facial recognition AI. That laid the technical groundwork for adversarial filters, which adjust photos to prevent them from being recognized by software. The developers of Glaze and Nightshade, they\u2019d previously released one of these tools, called Fawkes, after the V for Vendetta Guy Fawkes mask."]},{"begin":"274.240","end":"276.120","lines":["Another great name."]},{"begin":"276.120","end":"278.680","lines":["Yeah it\u2019s very into, like, the tech-dystopia world."]},{"begin":"278.680","end":"280.160","lines":["Totally."]},{"begin":"280.160","end":"296.720","lines":["Fawkes cloaked faces, and in 2023, the research team started hearing from artists asking if Fawkes would work help to hide their work from AI too. Initially, you know, the answer was no, but it did prompt the computer scientists to begin developing programs that could help artists cloak work."]},{"begin":"296.720","end":"298.800","lines":["So what do these tools do?"]},{"begin":"298.800","end":"314.040","lines":["Glaze and Nightshade, they do slightly different things, but let's start with the similarities. Both programs apply filters. They alter the pixels in digital pictures in subtle ways that are confusing to machine learning models but unobtrusive (mostly) to humans."]},{"begin":"314.040","end":"316.920","lines":["Very cool in theory, but how does it work?"]},{"begin":"316.920","end":"328.640","lines":["You know how, with optical illusions, a tiny tweak can suddenly make you see a totally different thing? Feltman: Ah yes, like the infamous dress that was definitely blue and black, and not white and gold at all."]},{"begin":"328.640","end":"342.680","lines":["Right there with you. Yeah, so optical illusions happen because human perception is imperfect, we have these quirks inherent to how our brains interpret what we see. For instance, you know, people have a tendency to see human faces in inanimate objects."]},{"begin":"342.680","end":"347.200","lines":["So true, like every US power outlet is just a scared lil guy."]},{"begin":"347.200","end":"353.120","lines":["Absolutely, yeah\u2013 power outlets, cars, mailboxes\u2013 all of them have their own faces and personalities."]},{"begin":"353.120","end":"354.120","lines":["100%."]},{"begin":"354.120","end":"382.640","lines":["Computers don\u2019t see the world the same way that humans do, but they have their own perceptual vulnerabilities. And the developers of Glaze and Nightshade built an algorithm that figures out those quirks and the best way to exploit them, and then modifies an image accordingly. It\u2019s a delicate balancing act. You want to stump the AI model, but you also want to keep things stable enough that a human viewer doesn\u2019t notice much of a change. In fact, the developers kind of got to that balanced point through trial and error."]},{"begin":"382.640","end":"396.760","lines":["Yeah, that makes sense. It\u2019s really hard to mask and distort an image without masking and distorting an image. So they\u2019re able to do this in a way that we can\u2019t perceive, but what does that look like from the AI\u2019s perspective?"]},{"begin":"396.760","end":"423.280","lines":["Another great question.To train an image-generating AI model to pump out pictures, you give it lots of images along with descriptive text. The model learns to associate certain words with visual features\u2013 think shapes or colors, but really it\u2019s something else we can\u2019t necessarily perceive because it\u2019s a computer. And under the hood, all of these associations are stored within basically multidimensional maps. Similar concepts and types of features are clustered near one another."]},{"begin":"423.280","end":"433.480","lines":["With the algorithm that underlie Glaze and Nightshade, the computer scientists strategically force associations between unrelated concepts, so they move points on that multidimensional map closer and closer together."]},{"begin":"433.480","end":"437.280","lines":["Yeah, I think I can wrap my head around how that would confuse an AI model."]},{"begin":"437.280","end":"449.880","lines":["Yeah, it\u2019s all still a little hand wavey because what it really comes down to is some complex math. Ben Zhao, the lead researcher at University of Chicago behind these cloaking programs, said that developing the algorithms was akin to solving two sets of linear equations."]},{"begin":"449.880","end":"452.680","lines":["Not my strong suit. So I will take his word for it."]},{"begin":"452.680","end":"455.400","lines":["Me either. That\u2019s why we\u2019re at a podcast instead."]},{"begin":"455.400","end":"458.000","lines":["So why two tools? How are these different?"]},{"begin":"458.000","end":"483.320","lines":["Glaze came out first. It was kind of the entry, the foray, into this world. It\u2019s very focused on cloaking an artists\u2019 style. So this thing kept happening to prominent digital artists where someone would take an open source generative AI model and train it on just that artist\u2019s work. That gave them a tool for producing style mimics. Obviously this can mean fewer paid opportunities for the artist in question, but it also opens creators up to reputational threats."]},{"begin":"483.320","end":"490.480","lines":["You could use one of these style mimics to make it seem like an artist had created a really offensive image, or something else that they would never make."]},{"begin":"490.480","end":"492.640","lines":["That sounds like such a nightmare."]},{"begin":"492.640","end":"515.640","lines":["Absolutely, in the same nightmare zone as deep fakes and everything happening with generative AI right now. So because of that, Zhao and his colleagues put out Glaze, which tricks AI models into perceiving the wrong style. Let\u2019s say your aesthetic is very cutesy, and bubbly and cartoon-ey. If you Glaze your work, an AI model might instead see Picasso-esque cubism. It makes it way harder to train style mimics."]},{"begin":"515.640","end":"523.200","lines":["Very cool. You mentioned that these tools can also play a little bit of offense against AI art generators. Is that where Nightshade comes in?"]},{"begin":"523.200","end":"545.040","lines":["That\u2019s right. An image cloaked in Nightshade will teach AI to incorrectly associate not just styles but also fundamental ideas and images. As a hypothetical example, it would only take a few hundred Nightshade-treated images to retrain a model to think cats are dogs. Zhao says that hundreds of thousands of people have already downloaded and begun deploying Nightshade."]},{"begin":"545.040","end":"561.360","lines":["And so his hope\u2013 and his co-researcher\u2019s hope and the artist\u2019s hope\u2013 is that with all of these images out there, it will become costly enough and annoying enough for AI companies to weed through masked picture, they\u2019ll be more incentivized to pay artists willing to license their work for training instead of just trawling the entire web."]},{"begin":"561.360","end":"564.680","lines":["And if nothing else, it\u2019s just very satisfying."]},{"begin":"564.680","end":"567.360","lines":["Yeah, it\u2019s catharsis at some baseline level."]},{"begin":"567.360","end":"575.040","lines":["Yeah, so it sounds like the idea is to kind of even out the power differential between AI developers and artists, is that right?"]},{"begin":"575.040","end":"606.560","lines":["Yeah, these tools, they definitely tip the balance a little bit, but they\u2019re certainly not a complete solution\u2013they\u2019re more like a stop gap. For one, artists can\u2019t retroactively protect any art that\u2019s already been hoovered up into AI training datasets, they can only apply these tools to newer work. Plus, AI technology is advancing super super fast. I spoke with some AI experts who were quick to point out that neither Glaze nor Nightshade are future proof. They could be compromised moving forward. AI models could just change into things that have different structure and architecture."]},{"begin":"606.560","end":"611.960","lines":["Already, one group of machine learning academics has partially succeeded at getting around the Glaze cloak."]},{"begin":"611.960","end":"614.840","lines":["Wow that was fast. That\u2019s a few months after it came out, right?"]},{"begin":"614.840","end":"622.760","lines":["Yeah, it\u2019s quick, though that\u2019s kind of the nature of digital security, as Zhao told me in his own words: \u201cit\u2019s always a cat-and-mouse game.\u201d"]},{"begin":"622.760","end":"648.200","lines":["And I guess even if Glaze and Nightshade continue to work perfectly, it\u2019s still unfair for artists to have to take those extra steps. Leffer: Yes, absolutely great point. I spoke with a professional illustrator, Mignon Zakuga, who\u2019s been really enthusiastic about Glaze and Nightshade. She was involved in beta testing, and still uses both cloaks regularly when she uploads her work. But even she said that passing images through the filters is not the greatest or easiest process."]},{"begin":"648.200","end":"664.920","lines":["It can take a couple of hours, and even though they\u2019re not supposed to be noticeable, often the visual changes are, at least to her. And especially to her, as the artist who made the image. So Zakuga told me it\u2019s a compromise she\u2019s willing to deal with for now. But clearly, artists deserve better, more robust protections."]},{"begin":"664.920","end":"670.360","lines":["Yeah like\u2013 and I know this is wild\u2013 but what about actual policy or legislation?"]},{"begin":"670.360","end":"695.480","lines":["100%, it would be great to get to a point where all of that is clarified especially in policy and law. But no one really knows what that should or will look like. Will copyright end up being enforced against AI? Do we need some whole new suite of protective laws? But at the very least, programs like Glaze and Nightshade, they offer us a little more time to figure that all out. [Clip: Show theme music]"]},{"begin":"695.480","end":"705.800","lines":["Science Quickly is produced by Jeff DelViscio, Tulika Bose, Rachel Feltman, Kelso Harper and Carin Leong. Our show is edited by Elah Feder and Alexa Lim. Our theme music was composed by Dominic Smith."]},{"begin":"705.800","end":"716.240","lines":["Don\u2019t forget to subscribe to Science Quickly wherever you get your podcasts. For more in-depth science news and features, go to ScientificAmerican.com. And if you like the show, give us a rating or review!"]},{"begin":"716.240","end":"725.920","lines":["For Scientific American\u2019s Science Quickly, I\u2019m Lauren Leffer."]},{"begin":"725.920","end":"734.320","lines":["I\u2019m Rachel Feltman. See you next time!"]}],"duration":734}